; ModuleID = './KH/ENAJGGLLBDKDADOANPPKIIABCILKIKBONPBNA/Convolution2D_kernel/32-8-1-goffs0-smallgrid/parallel.bc'
source_filename = "parallel_bc"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nounwind readnone speculatable willreturn
declare float @llvm.fmuladd.f32(float, float, float) #0

; Function Attrs: alwaysinline nofree norecurse nounwind
define void @_pocl_kernel_Convolution2D_kernel(float* nocapture readonly %0, float* nocapture %1, i32 %2, i32 %3, { [3 x i64], [3 x i64], [3 x i64], i8*, i32*, i32, i32 }* nocapture readnone %4, i64 %5, i64 %6, i64 %7) local_unnamed_addr #1 !kernel_arg_addr_space !5 !kernel_arg_access_qual !6 !kernel_arg_type !7 !kernel_arg_base_type !8 !kernel_arg_type_qual !9 !kernel_arg_name !10 !pocl_generated !11 {
  %mul.i.i = shl i64 %5, 5
  %mul3.i.i = shl i64 %6, 3
  %9 = trunc i64 %6 to i32
  %10 = shl i32 %9, 3
  %11 = add nsw i32 %10, -1
  %12 = mul i32 %11, %3
  %13 = trunc i64 %5 to i32
  %14 = shl i32 %13, 5
  %15 = add i32 %12, %14
  %16 = add i32 %15, -1
  %17 = zext i32 %3 to i64
  %18 = zext i32 %12 to i64
  %19 = sext i32 %14 to i64
  %20 = add nsw i64 %18, %19
  %21 = add i32 %12, %14
  %22 = add i32 %21, 1
  %23 = mul i32 %9, %3
  %24 = shl i32 %23, 3
  %25 = add i32 %24, %14
  %26 = add i32 %25, -8
  %27 = or i32 %26, 7
  %28 = zext i32 %24 to i64
  %29 = add nsw i64 %28, %19
  %30 = add nsw i32 %24, %14
  %31 = or i32 %30, 1
  %32 = or i32 %10, 1
  %33 = mul i32 %32, %3
  %34 = add i32 %33, %14
  %35 = add i32 %34, -1
  %36 = zext i32 %33 to i64
  %37 = add nsw i64 %36, %19
  %38 = add i32 %34, 1
  %39 = trunc i64 %mul.i.i to i32
  %40 = add nsw i32 %39, -1
  %41 = or i32 %39, 1
  %42 = trunc i64 %mul.i.i to i32
  %43 = or i32 %42, 8
  %44 = add nsw i32 %43, -1
  %45 = or i32 %42, 9
  %46 = trunc i64 %mul.i.i to i32
  %47 = or i32 %46, 16
  %48 = add nsw i32 %47, -1
  %49 = or i32 %46, 17
  %50 = trunc i64 %mul.i.i to i32
  %51 = or i32 %50, 24
  %52 = add nsw i32 %51, -1
  %53 = or i32 %50, 25
  br label %pregion_for_entry.pregion_for_init.i

pregion_for_entry.pregion_for_init.i:             ; preds = %pregion_for_end.i, %8
  %_local_id_y.0 = phi i64 [ 0, %8 ], [ %273, %pregion_for_end.i ]
  %54 = mul i64 %_local_id_y.0, %17
  %add6.i.i = add nuw nsw i64 %_local_id_y.0, %mul3.i.i
  %conv2.i = trunc i64 %add6.i.i to i32
  %sub.i = add nsw i32 %conv2.i, -1
  %mul.i = mul nsw i32 %sub.i, %3
  %mul20.i = mul nsw i32 %conv2.i, %3
  %add40.i = add nsw i32 %conv2.i, 1
  %mul41.i = mul nsw i32 %add40.i, %3
  %55 = trunc i64 %54 to i32
  %56 = add i32 %38, %55
  %57 = add i64 %37, %54
  %58 = trunc i64 %57 to i32
  %59 = trunc i64 %54 to i32
  %60 = add i32 %35, %59
  %61 = trunc i64 %54 to i32
  %62 = add i32 %31, %61
  %63 = add i64 %29, %54
  %64 = trunc i64 %63 to i32
  %65 = trunc i64 %54 to i32
  %66 = add i32 %27, %65
  %67 = trunc i64 %54 to i32
  %68 = add i32 %22, %67
  %69 = add i64 %20, %54
  %70 = trunc i64 %69 to i32
  %71 = trunc i64 %54 to i32
  %72 = add i32 %16, %71
  %73 = insertelement <8 x i32> undef, i32 %72, i32 0
  %74 = insertelement <8 x i32> %73, i32 %70, i32 1
  %75 = insertelement <8 x i32> %74, i32 %68, i32 2
  %76 = insertelement <8 x i32> %75, i32 %66, i32 3
  %77 = insertelement <8 x i32> %76, i32 %64, i32 4
  %78 = insertelement <8 x i32> %77, i32 %62, i32 5
  %79 = insertelement <8 x i32> %78, i32 %60, i32 6
  %80 = insertelement <8 x i32> %79, i32 %58, i32 7
  %81 = icmp sgt <8 x i32> %80, <i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616>
  %82 = icmp sgt i32 %56, 2147483616
  %83 = call i1 @llvm.experimental.vector.reduce.or.v8i1(<8 x i1> %81)
  %84 = or i1 %83, %82
  br i1 %84, label %pregion_for_entry.entry.i.preheader, label %vector.body

pregion_for_entry.entry.i.preheader:              ; preds = %pregion_for_entry.pregion_for_init.i
  br label %pregion_for_entry.entry.i

vector.body:                                      ; preds = %pregion_for_entry.pregion_for_init.i
  %85 = add nsw i32 %40, %mul.i
  %86 = sext i32 %85 to i64
  %87 = getelementptr inbounds float, float* %0, i64 %86
  %88 = bitcast float* %87 to <8 x float>*
  %wide.load = load <8 x float>, <8 x float>* %88, align 4, !tbaa !12, !llvm.access.group !16
  %89 = add nsw i32 %mul.i, %39
  %90 = sext i32 %89 to i64
  %91 = getelementptr inbounds float, float* %0, i64 %90
  %92 = bitcast float* %91 to <8 x float>*
  %wide.load26 = load <8 x float>, <8 x float>* %92, align 4, !tbaa !12, !llvm.access.group !16
  %93 = fmul <8 x float> %wide.load26, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %94 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load, <8 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>, <8 x float> %93)
  %95 = add nsw i32 %41, %mul.i
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds float, float* %0, i64 %96
  %98 = bitcast float* %97 to <8 x float>*
  %wide.load27 = load <8 x float>, <8 x float>* %98, align 4, !tbaa !12, !llvm.access.group !16
  %99 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load27, <8 x float> <float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000>, <8 x float> %94)
  %100 = add nsw i32 %40, %mul20.i
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds float, float* %0, i64 %101
  %103 = bitcast float* %102 to <8 x float>*
  %wide.load28 = load <8 x float>, <8 x float>* %103, align 4, !tbaa !12, !llvm.access.group !16
  %104 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load28, <8 x float> <float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000>, <8 x float> %99)
  %105 = add nsw i32 %mul20.i, %39
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds float, float* %0, i64 %106
  %108 = bitcast float* %107 to <8 x float>*
  %wide.load29 = load <8 x float>, <8 x float>* %108, align 4, !tbaa !12, !llvm.access.group !16
  %109 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load29, <8 x float> <float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000>, <8 x float> %104)
  %110 = add nsw i32 %41, %mul20.i
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds float, float* %0, i64 %111
  %113 = bitcast float* %112 to <8 x float>*
  %wide.load30 = load <8 x float>, <8 x float>* %113, align 4, !tbaa !12, !llvm.access.group !16
  %114 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load30, <8 x float> <float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000>, <8 x float> %109)
  %115 = add nsw i32 %40, %mul41.i
  %116 = sext i32 %115 to i64
  %117 = getelementptr inbounds float, float* %0, i64 %116
  %118 = bitcast float* %117 to <8 x float>*
  %wide.load31 = load <8 x float>, <8 x float>* %118, align 4, !tbaa !12, !llvm.access.group !16
  %119 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load31, <8 x float> <float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000>, <8 x float> %114)
  %120 = add nsw i32 %mul41.i, %39
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds float, float* %0, i64 %121
  %123 = bitcast float* %122 to <8 x float>*
  %wide.load32 = load <8 x float>, <8 x float>* %123, align 4, !tbaa !12, !llvm.access.group !16
  %124 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load32, <8 x float> <float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000>, <8 x float> %119)
  %125 = add nsw i32 %41, %mul41.i
  %126 = sext i32 %125 to i64
  %127 = getelementptr inbounds float, float* %0, i64 %126
  %128 = bitcast float* %127 to <8 x float>*
  %wide.load33 = load <8 x float>, <8 x float>* %128, align 4, !tbaa !12, !llvm.access.group !16
  %129 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load33, <8 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <8 x float> %124)
  %130 = getelementptr inbounds float, float* %1, i64 %106
  %131 = bitcast float* %130 to <8 x float>*
  store <8 x float> %129, <8 x float>* %131, align 4, !tbaa !12, !llvm.access.group !16
  %132 = add nsw i32 %44, %mul.i
  %133 = sext i32 %132 to i64
  %134 = getelementptr inbounds float, float* %0, i64 %133
  %135 = bitcast float* %134 to <8 x float>*
  %wide.load.1 = load <8 x float>, <8 x float>* %135, align 4, !tbaa !12, !llvm.access.group !16
  %136 = add nsw i32 %mul.i, %43
  %137 = sext i32 %136 to i64
  %138 = getelementptr inbounds float, float* %0, i64 %137
  %139 = bitcast float* %138 to <8 x float>*
  %wide.load26.1 = load <8 x float>, <8 x float>* %139, align 4, !tbaa !12, !llvm.access.group !16
  %140 = fmul <8 x float> %wide.load26.1, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %141 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load.1, <8 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>, <8 x float> %140)
  %142 = add nsw i32 %45, %mul.i
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds float, float* %0, i64 %143
  %145 = bitcast float* %144 to <8 x float>*
  %wide.load27.1 = load <8 x float>, <8 x float>* %145, align 4, !tbaa !12, !llvm.access.group !16
  %146 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load27.1, <8 x float> <float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000>, <8 x float> %141)
  %147 = add nsw i32 %44, %mul20.i
  %148 = sext i32 %147 to i64
  %149 = getelementptr inbounds float, float* %0, i64 %148
  %150 = bitcast float* %149 to <8 x float>*
  %wide.load28.1 = load <8 x float>, <8 x float>* %150, align 4, !tbaa !12, !llvm.access.group !16
  %151 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load28.1, <8 x float> <float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000>, <8 x float> %146)
  %152 = add nsw i32 %mul20.i, %43
  %153 = sext i32 %152 to i64
  %154 = getelementptr inbounds float, float* %0, i64 %153
  %155 = bitcast float* %154 to <8 x float>*
  %wide.load29.1 = load <8 x float>, <8 x float>* %155, align 4, !tbaa !12, !llvm.access.group !16
  %156 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load29.1, <8 x float> <float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000>, <8 x float> %151)
  %157 = add nsw i32 %45, %mul20.i
  %158 = sext i32 %157 to i64
  %159 = getelementptr inbounds float, float* %0, i64 %158
  %160 = bitcast float* %159 to <8 x float>*
  %wide.load30.1 = load <8 x float>, <8 x float>* %160, align 4, !tbaa !12, !llvm.access.group !16
  %161 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load30.1, <8 x float> <float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000>, <8 x float> %156)
  %162 = add nsw i32 %44, %mul41.i
  %163 = sext i32 %162 to i64
  %164 = getelementptr inbounds float, float* %0, i64 %163
  %165 = bitcast float* %164 to <8 x float>*
  %wide.load31.1 = load <8 x float>, <8 x float>* %165, align 4, !tbaa !12, !llvm.access.group !16
  %166 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load31.1, <8 x float> <float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000>, <8 x float> %161)
  %167 = add nsw i32 %mul41.i, %43
  %168 = sext i32 %167 to i64
  %169 = getelementptr inbounds float, float* %0, i64 %168
  %170 = bitcast float* %169 to <8 x float>*
  %wide.load32.1 = load <8 x float>, <8 x float>* %170, align 4, !tbaa !12, !llvm.access.group !16
  %171 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load32.1, <8 x float> <float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000>, <8 x float> %166)
  %172 = add nsw i32 %45, %mul41.i
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds float, float* %0, i64 %173
  %175 = bitcast float* %174 to <8 x float>*
  %wide.load33.1 = load <8 x float>, <8 x float>* %175, align 4, !tbaa !12, !llvm.access.group !16
  %176 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load33.1, <8 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <8 x float> %171)
  %177 = getelementptr inbounds float, float* %1, i64 %153
  %178 = bitcast float* %177 to <8 x float>*
  store <8 x float> %176, <8 x float>* %178, align 4, !tbaa !12, !llvm.access.group !16
  %179 = add nsw i32 %48, %mul.i
  %180 = sext i32 %179 to i64
  %181 = getelementptr inbounds float, float* %0, i64 %180
  %182 = bitcast float* %181 to <8 x float>*
  %wide.load.2 = load <8 x float>, <8 x float>* %182, align 4, !tbaa !12, !llvm.access.group !16
  %183 = add nsw i32 %mul.i, %47
  %184 = sext i32 %183 to i64
  %185 = getelementptr inbounds float, float* %0, i64 %184
  %186 = bitcast float* %185 to <8 x float>*
  %wide.load26.2 = load <8 x float>, <8 x float>* %186, align 4, !tbaa !12, !llvm.access.group !16
  %187 = fmul <8 x float> %wide.load26.2, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %188 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load.2, <8 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>, <8 x float> %187)
  %189 = add nsw i32 %49, %mul.i
  %190 = sext i32 %189 to i64
  %191 = getelementptr inbounds float, float* %0, i64 %190
  %192 = bitcast float* %191 to <8 x float>*
  %wide.load27.2 = load <8 x float>, <8 x float>* %192, align 4, !tbaa !12, !llvm.access.group !16
  %193 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load27.2, <8 x float> <float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000>, <8 x float> %188)
  %194 = add nsw i32 %48, %mul20.i
  %195 = sext i32 %194 to i64
  %196 = getelementptr inbounds float, float* %0, i64 %195
  %197 = bitcast float* %196 to <8 x float>*
  %wide.load28.2 = load <8 x float>, <8 x float>* %197, align 4, !tbaa !12, !llvm.access.group !16
  %198 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load28.2, <8 x float> <float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000>, <8 x float> %193)
  %199 = add nsw i32 %mul20.i, %47
  %200 = sext i32 %199 to i64
  %201 = getelementptr inbounds float, float* %0, i64 %200
  %202 = bitcast float* %201 to <8 x float>*
  %wide.load29.2 = load <8 x float>, <8 x float>* %202, align 4, !tbaa !12, !llvm.access.group !16
  %203 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load29.2, <8 x float> <float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000>, <8 x float> %198)
  %204 = add nsw i32 %49, %mul20.i
  %205 = sext i32 %204 to i64
  %206 = getelementptr inbounds float, float* %0, i64 %205
  %207 = bitcast float* %206 to <8 x float>*
  %wide.load30.2 = load <8 x float>, <8 x float>* %207, align 4, !tbaa !12, !llvm.access.group !16
  %208 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load30.2, <8 x float> <float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000>, <8 x float> %203)
  %209 = add nsw i32 %48, %mul41.i
  %210 = sext i32 %209 to i64
  %211 = getelementptr inbounds float, float* %0, i64 %210
  %212 = bitcast float* %211 to <8 x float>*
  %wide.load31.2 = load <8 x float>, <8 x float>* %212, align 4, !tbaa !12, !llvm.access.group !16
  %213 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load31.2, <8 x float> <float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000>, <8 x float> %208)
  %214 = add nsw i32 %mul41.i, %47
  %215 = sext i32 %214 to i64
  %216 = getelementptr inbounds float, float* %0, i64 %215
  %217 = bitcast float* %216 to <8 x float>*
  %wide.load32.2 = load <8 x float>, <8 x float>* %217, align 4, !tbaa !12, !llvm.access.group !16
  %218 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load32.2, <8 x float> <float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000>, <8 x float> %213)
  %219 = add nsw i32 %49, %mul41.i
  %220 = sext i32 %219 to i64
  %221 = getelementptr inbounds float, float* %0, i64 %220
  %222 = bitcast float* %221 to <8 x float>*
  %wide.load33.2 = load <8 x float>, <8 x float>* %222, align 4, !tbaa !12, !llvm.access.group !16
  %223 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load33.2, <8 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <8 x float> %218)
  %224 = getelementptr inbounds float, float* %1, i64 %200
  %225 = bitcast float* %224 to <8 x float>*
  store <8 x float> %223, <8 x float>* %225, align 4, !tbaa !12, !llvm.access.group !16
  %226 = add nsw i32 %52, %mul.i
  %227 = sext i32 %226 to i64
  %228 = getelementptr inbounds float, float* %0, i64 %227
  %229 = bitcast float* %228 to <8 x float>*
  %wide.load.3 = load <8 x float>, <8 x float>* %229, align 4, !tbaa !12, !llvm.access.group !16
  %230 = add nsw i32 %mul.i, %51
  %231 = sext i32 %230 to i64
  %232 = getelementptr inbounds float, float* %0, i64 %231
  %233 = bitcast float* %232 to <8 x float>*
  %wide.load26.3 = load <8 x float>, <8 x float>* %233, align 4, !tbaa !12, !llvm.access.group !16
  %234 = fmul <8 x float> %wide.load26.3, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %235 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load.3, <8 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>, <8 x float> %234)
  %236 = add nsw i32 %53, %mul.i
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds float, float* %0, i64 %237
  %239 = bitcast float* %238 to <8 x float>*
  %wide.load27.3 = load <8 x float>, <8 x float>* %239, align 4, !tbaa !12, !llvm.access.group !16
  %240 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load27.3, <8 x float> <float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000>, <8 x float> %235)
  %241 = add nsw i32 %52, %mul20.i
  %242 = sext i32 %241 to i64
  %243 = getelementptr inbounds float, float* %0, i64 %242
  %244 = bitcast float* %243 to <8 x float>*
  %wide.load28.3 = load <8 x float>, <8 x float>* %244, align 4, !tbaa !12, !llvm.access.group !16
  %245 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load28.3, <8 x float> <float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000>, <8 x float> %240)
  %246 = add nsw i32 %mul20.i, %51
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds float, float* %0, i64 %247
  %249 = bitcast float* %248 to <8 x float>*
  %wide.load29.3 = load <8 x float>, <8 x float>* %249, align 4, !tbaa !12, !llvm.access.group !16
  %250 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load29.3, <8 x float> <float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000>, <8 x float> %245)
  %251 = add nsw i32 %53, %mul20.i
  %252 = sext i32 %251 to i64
  %253 = getelementptr inbounds float, float* %0, i64 %252
  %254 = bitcast float* %253 to <8 x float>*
  %wide.load30.3 = load <8 x float>, <8 x float>* %254, align 4, !tbaa !12, !llvm.access.group !16
  %255 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load30.3, <8 x float> <float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000>, <8 x float> %250)
  %256 = add nsw i32 %52, %mul41.i
  %257 = sext i32 %256 to i64
  %258 = getelementptr inbounds float, float* %0, i64 %257
  %259 = bitcast float* %258 to <8 x float>*
  %wide.load31.3 = load <8 x float>, <8 x float>* %259, align 4, !tbaa !12, !llvm.access.group !16
  %260 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load31.3, <8 x float> <float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000>, <8 x float> %255)
  %261 = add nsw i32 %mul41.i, %51
  %262 = sext i32 %261 to i64
  %263 = getelementptr inbounds float, float* %0, i64 %262
  %264 = bitcast float* %263 to <8 x float>*
  %wide.load32.3 = load <8 x float>, <8 x float>* %264, align 4, !tbaa !12, !llvm.access.group !16
  %265 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load32.3, <8 x float> <float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000>, <8 x float> %260)
  %266 = add nsw i32 %53, %mul41.i
  %267 = sext i32 %266 to i64
  %268 = getelementptr inbounds float, float* %0, i64 %267
  %269 = bitcast float* %268 to <8 x float>*
  %wide.load33.3 = load <8 x float>, <8 x float>* %269, align 4, !tbaa !12, !llvm.access.group !16
  %270 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load33.3, <8 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <8 x float> %265)
  %271 = getelementptr inbounds float, float* %1, i64 %247
  %272 = bitcast float* %271 to <8 x float>*
  store <8 x float> %270, <8 x float>* %272, align 4, !tbaa !12, !llvm.access.group !16
  br label %pregion_for_end.i

pregion_for_end.i.loopexit:                       ; preds = %pregion_for_entry.entry.i
  br label %pregion_for_end.i

pregion_for_end.i:                                ; preds = %pregion_for_end.i.loopexit, %vector.body
  %273 = add nuw nsw i64 %_local_id_y.0, 1
  %exitcond1.not = icmp eq i64 %273, 8
  br i1 %exitcond1.not, label %Convolution2D_kernel.exit, label %pregion_for_entry.pregion_for_init.i, !llvm.loop !19

pregion_for_entry.entry.i:                        ; preds = %pregion_for_entry.entry.i, %pregion_for_entry.entry.i.preheader
  %_local_id_x.0 = phi i64 [ %291, %pregion_for_entry.entry.i ], [ 0, %pregion_for_entry.entry.i.preheader ]
  %add1.i.i = add nuw nsw i64 %_local_id_x.0, %mul.i.i
  %conv.i = trunc i64 %add1.i.i to i32
  %sub3.i = add nsw i32 %conv.i, -1
  %add.i = add nsw i32 %sub3.i, %mul.i
  %idxprom.i = sext i32 %add.i to i64
  %arrayidx.i = getelementptr inbounds float, float* %0, i64 %idxprom.i
  %274 = load float, float* %arrayidx.i, align 4, !tbaa !12, !llvm.access.group !16
  %add8.i = add nsw i32 %mul.i, %conv.i
  %idxprom9.i = sext i32 %add8.i to i64
  %arrayidx10.i = getelementptr inbounds float, float* %0, i64 %idxprom9.i
  %275 = load float, float* %arrayidx10.i, align 4, !tbaa !12, !llvm.access.group !16
  %mul11.i = fmul float %275, 5.000000e-01
  %276 = tail call float @llvm.fmuladd.f32(float %274, float 0x3FC99999A0000000, float %mul11.i) #4
  %add14.i = add nsw i32 %conv.i, 1
  %add15.i = add nsw i32 %add14.i, %mul.i
  %idxprom16.i = sext i32 %add15.i to i64
  %arrayidx17.i = getelementptr inbounds float, float* %0, i64 %idxprom16.i
  %277 = load float, float* %arrayidx17.i, align 4, !tbaa !12, !llvm.access.group !16
  %278 = tail call float @llvm.fmuladd.f32(float %277, float 0xBFE99999A0000000, float %276) #4
  %add22.i = add nsw i32 %sub3.i, %mul20.i
  %idxprom23.i = sext i32 %add22.i to i64
  %arrayidx24.i = getelementptr inbounds float, float* %0, i64 %idxprom23.i
  %279 = load float, float* %arrayidx24.i, align 4, !tbaa !12, !llvm.access.group !16
  %280 = tail call float @llvm.fmuladd.f32(float %279, float 0xBFD3333340000000, float %278) #4
  %add29.i = add nsw i32 %mul20.i, %conv.i
  %idxprom30.i = sext i32 %add29.i to i64
  %arrayidx31.i = getelementptr inbounds float, float* %0, i64 %idxprom30.i
  %281 = load float, float* %arrayidx31.i, align 4, !tbaa !12, !llvm.access.group !16
  %282 = tail call float @llvm.fmuladd.f32(float %281, float 0x3FE3333340000000, float %280) #4
  %add36.i = add nsw i32 %add14.i, %mul20.i
  %idxprom37.i = sext i32 %add36.i to i64
  %arrayidx38.i = getelementptr inbounds float, float* %0, i64 %idxprom37.i
  %283 = load float, float* %arrayidx38.i, align 4, !tbaa !12, !llvm.access.group !16
  %284 = tail call float @llvm.fmuladd.f32(float %283, float 0xBFECCCCCC0000000, float %282) #4
  %add43.i = add nsw i32 %sub3.i, %mul41.i
  %idxprom44.i = sext i32 %add43.i to i64
  %arrayidx45.i = getelementptr inbounds float, float* %0, i64 %idxprom44.i
  %285 = load float, float* %arrayidx45.i, align 4, !tbaa !12, !llvm.access.group !16
  %286 = tail call float @llvm.fmuladd.f32(float %285, float 0x3FD99999A0000000, float %284) #4
  %add50.i = add nsw i32 %mul41.i, %conv.i
  %idxprom51.i = sext i32 %add50.i to i64
  %arrayidx52.i = getelementptr inbounds float, float* %0, i64 %idxprom51.i
  %287 = load float, float* %arrayidx52.i, align 4, !tbaa !12, !llvm.access.group !16
  %288 = tail call float @llvm.fmuladd.f32(float %287, float 0x3FE6666660000000, float %286) #4
  %add57.i = add nsw i32 %add14.i, %mul41.i
  %idxprom58.i = sext i32 %add57.i to i64
  %arrayidx59.i = getelementptr inbounds float, float* %0, i64 %idxprom58.i
  %289 = load float, float* %arrayidx59.i, align 4, !tbaa !12, !llvm.access.group !16
  %290 = tail call float @llvm.fmuladd.f32(float %289, float 0x3FB99999A0000000, float %288) #4
  %arrayidx64.i = getelementptr inbounds float, float* %1, i64 %idxprom30.i
  store float %290, float* %arrayidx64.i, align 4, !tbaa !12, !llvm.access.group !16
  %291 = add nuw nsw i64 %_local_id_x.0, 1
  %exitcond.not = icmp eq i64 %291, 32
  br i1 %exitcond.not, label %pregion_for_end.i.loopexit, label %pregion_for_entry.entry.i, !llvm.loop !21

Convolution2D_kernel.exit:                        ; preds = %pregion_for_end.i
  ret void
}

; Function Attrs: nofree nounwind
define void @_pocl_kernel_Convolution2D_kernel_workgroup(i8** nocapture readonly %0, { [3 x i64], [3 x i64], [3 x i64], i8*, i32*, i32, i32 }* nocapture readnone %1, i64 %2, i64 %3, i64 %4) local_unnamed_addr #2 {
  %6 = bitcast i8** %0 to float***
  %7 = load float**, float*** %6, align 8
  %8 = load float*, float** %7, align 8
  %9 = getelementptr i8*, i8** %0, i64 1
  %10 = bitcast i8** %9 to float***
  %11 = load float**, float*** %10, align 8
  %12 = load float*, float** %11, align 8
  %13 = getelementptr i8*, i8** %0, i64 3
  %14 = bitcast i8** %13 to i32**
  %15 = load i32*, i32** %14, align 8
  %16 = load i32, i32* %15, align 4
  %mul.i.i.i = shl i64 %2, 5
  %mul3.i.i.i = shl i64 %3, 3
  %17 = trunc i64 %3 to i32
  %18 = shl i32 %17, 3
  %19 = add nsw i32 %18, -1
  %20 = mul i32 %16, %19
  %21 = trunc i64 %2 to i32
  %22 = shl i32 %21, 5
  %23 = add i32 %20, %22
  %24 = add i32 %23, -1
  %25 = zext i32 %16 to i64
  %26 = zext i32 %20 to i64
  %27 = sext i32 %22 to i64
  %28 = add nsw i64 %26, %27
  %29 = add i32 %20, %22
  %30 = add i32 %29, 1
  %31 = mul i32 %16, %17
  %32 = shl i32 %31, 3
  %33 = add i32 %32, %22
  %34 = add i32 %33, -8
  %35 = or i32 %34, 7
  %36 = zext i32 %32 to i64
  %37 = add nsw i64 %36, %27
  %38 = add nsw i32 %32, %22
  %39 = or i32 %38, 1
  %40 = or i32 %18, 1
  %41 = mul i32 %16, %40
  %42 = add i32 %41, %22
  %43 = add i32 %42, -1
  %44 = zext i32 %41 to i64
  %45 = add nsw i64 %44, %27
  %46 = add i32 %42, 1
  %47 = trunc i64 %mul.i.i.i to i32
  %48 = add nsw i32 %47, -1
  %49 = or i32 %47, 1
  %50 = trunc i64 %mul.i.i.i to i32
  %51 = or i32 %50, 8
  %52 = add nsw i32 %51, -1
  %53 = or i32 %50, 9
  %54 = trunc i64 %mul.i.i.i to i32
  %55 = or i32 %54, 16
  %56 = add nsw i32 %55, -1
  %57 = or i32 %54, 17
  %58 = trunc i64 %mul.i.i.i to i32
  %59 = or i32 %58, 24
  %60 = add nsw i32 %59, -1
  %61 = or i32 %58, 25
  br label %pregion_for_entry.pregion_for_init.i.i

pregion_for_entry.pregion_for_init.i.i:           ; preds = %pregion_for_end.i.i, %5
  %_local_id_y.i.0 = phi i64 [ 0, %5 ], [ %281, %pregion_for_end.i.i ]
  %62 = mul i64 %_local_id_y.i.0, %25
  %add6.i.i.i = add nuw nsw i64 %_local_id_y.i.0, %mul3.i.i.i
  %conv2.i.i = trunc i64 %add6.i.i.i to i32
  %sub.i.i = add nsw i32 %conv2.i.i, -1
  %mul.i.i = mul nsw i32 %sub.i.i, %16
  %mul20.i.i = mul nsw i32 %16, %conv2.i.i
  %add40.i.i = add nsw i32 %conv2.i.i, 1
  %mul41.i.i = mul nsw i32 %add40.i.i, %16
  %63 = trunc i64 %62 to i32
  %64 = add i32 %46, %63
  %65 = add i64 %45, %62
  %66 = trunc i64 %65 to i32
  %67 = trunc i64 %62 to i32
  %68 = add i32 %43, %67
  %69 = trunc i64 %62 to i32
  %70 = add i32 %39, %69
  %71 = add i64 %37, %62
  %72 = trunc i64 %71 to i32
  %73 = trunc i64 %62 to i32
  %74 = add i32 %35, %73
  %75 = trunc i64 %62 to i32
  %76 = add i32 %30, %75
  %77 = add i64 %28, %62
  %78 = trunc i64 %77 to i32
  %79 = trunc i64 %62 to i32
  %80 = add i32 %24, %79
  %81 = insertelement <8 x i32> undef, i32 %80, i32 0
  %82 = insertelement <8 x i32> %81, i32 %78, i32 1
  %83 = insertelement <8 x i32> %82, i32 %76, i32 2
  %84 = insertelement <8 x i32> %83, i32 %74, i32 3
  %85 = insertelement <8 x i32> %84, i32 %72, i32 4
  %86 = insertelement <8 x i32> %85, i32 %70, i32 5
  %87 = insertelement <8 x i32> %86, i32 %68, i32 6
  %88 = insertelement <8 x i32> %87, i32 %66, i32 7
  %89 = icmp sgt <8 x i32> %88, <i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616>
  %90 = icmp sgt i32 %64, 2147483616
  %91 = call i1 @llvm.experimental.vector.reduce.or.v8i1(<8 x i1> %89)
  %92 = or i1 %91, %90
  br i1 %92, label %pregion_for_entry.entry.i.i.preheader, label %vector.body

pregion_for_entry.entry.i.i.preheader:            ; preds = %pregion_for_entry.pregion_for_init.i.i
  br label %pregion_for_entry.entry.i.i

vector.body:                                      ; preds = %pregion_for_entry.pregion_for_init.i.i
  %93 = add nsw i32 %48, %mul.i.i
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds float, float* %8, i64 %94
  %96 = bitcast float* %95 to <8 x float>*
  %wide.load = load <8 x float>, <8 x float>* %96, align 4, !tbaa !12, !llvm.access.group !16
  %97 = add nsw i32 %mul.i.i, %47
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds float, float* %8, i64 %98
  %100 = bitcast float* %99 to <8 x float>*
  %wide.load26 = load <8 x float>, <8 x float>* %100, align 4, !tbaa !12, !llvm.access.group !16
  %101 = fmul <8 x float> %wide.load26, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %102 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load, <8 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>, <8 x float> %101)
  %103 = add nsw i32 %49, %mul.i.i
  %104 = sext i32 %103 to i64
  %105 = getelementptr inbounds float, float* %8, i64 %104
  %106 = bitcast float* %105 to <8 x float>*
  %wide.load27 = load <8 x float>, <8 x float>* %106, align 4, !tbaa !12, !llvm.access.group !16
  %107 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load27, <8 x float> <float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000>, <8 x float> %102)
  %108 = add nsw i32 %48, %mul20.i.i
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds float, float* %8, i64 %109
  %111 = bitcast float* %110 to <8 x float>*
  %wide.load28 = load <8 x float>, <8 x float>* %111, align 4, !tbaa !12, !llvm.access.group !16
  %112 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load28, <8 x float> <float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000>, <8 x float> %107)
  %113 = add nsw i32 %mul20.i.i, %47
  %114 = sext i32 %113 to i64
  %115 = getelementptr inbounds float, float* %8, i64 %114
  %116 = bitcast float* %115 to <8 x float>*
  %wide.load29 = load <8 x float>, <8 x float>* %116, align 4, !tbaa !12, !llvm.access.group !16
  %117 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load29, <8 x float> <float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000>, <8 x float> %112)
  %118 = add nsw i32 %49, %mul20.i.i
  %119 = sext i32 %118 to i64
  %120 = getelementptr inbounds float, float* %8, i64 %119
  %121 = bitcast float* %120 to <8 x float>*
  %wide.load30 = load <8 x float>, <8 x float>* %121, align 4, !tbaa !12, !llvm.access.group !16
  %122 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load30, <8 x float> <float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000>, <8 x float> %117)
  %123 = add nsw i32 %48, %mul41.i.i
  %124 = sext i32 %123 to i64
  %125 = getelementptr inbounds float, float* %8, i64 %124
  %126 = bitcast float* %125 to <8 x float>*
  %wide.load31 = load <8 x float>, <8 x float>* %126, align 4, !tbaa !12, !llvm.access.group !16
  %127 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load31, <8 x float> <float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000>, <8 x float> %122)
  %128 = add nsw i32 %mul41.i.i, %47
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds float, float* %8, i64 %129
  %131 = bitcast float* %130 to <8 x float>*
  %wide.load32 = load <8 x float>, <8 x float>* %131, align 4, !tbaa !12, !llvm.access.group !16
  %132 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load32, <8 x float> <float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000>, <8 x float> %127)
  %133 = add nsw i32 %49, %mul41.i.i
  %134 = sext i32 %133 to i64
  %135 = getelementptr inbounds float, float* %8, i64 %134
  %136 = bitcast float* %135 to <8 x float>*
  %wide.load33 = load <8 x float>, <8 x float>* %136, align 4, !tbaa !12, !llvm.access.group !16
  %137 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load33, <8 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <8 x float> %132)
  %138 = getelementptr inbounds float, float* %12, i64 %114
  %139 = bitcast float* %138 to <8 x float>*
  store <8 x float> %137, <8 x float>* %139, align 4, !tbaa !12, !llvm.access.group !16
  %140 = add nsw i32 %52, %mul.i.i
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %8, i64 %141
  %143 = bitcast float* %142 to <8 x float>*
  %wide.load.1 = load <8 x float>, <8 x float>* %143, align 4, !tbaa !12, !llvm.access.group !16
  %144 = add nsw i32 %mul.i.i, %51
  %145 = sext i32 %144 to i64
  %146 = getelementptr inbounds float, float* %8, i64 %145
  %147 = bitcast float* %146 to <8 x float>*
  %wide.load26.1 = load <8 x float>, <8 x float>* %147, align 4, !tbaa !12, !llvm.access.group !16
  %148 = fmul <8 x float> %wide.load26.1, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %149 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load.1, <8 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>, <8 x float> %148)
  %150 = add nsw i32 %53, %mul.i.i
  %151 = sext i32 %150 to i64
  %152 = getelementptr inbounds float, float* %8, i64 %151
  %153 = bitcast float* %152 to <8 x float>*
  %wide.load27.1 = load <8 x float>, <8 x float>* %153, align 4, !tbaa !12, !llvm.access.group !16
  %154 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load27.1, <8 x float> <float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000>, <8 x float> %149)
  %155 = add nsw i32 %52, %mul20.i.i
  %156 = sext i32 %155 to i64
  %157 = getelementptr inbounds float, float* %8, i64 %156
  %158 = bitcast float* %157 to <8 x float>*
  %wide.load28.1 = load <8 x float>, <8 x float>* %158, align 4, !tbaa !12, !llvm.access.group !16
  %159 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load28.1, <8 x float> <float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000>, <8 x float> %154)
  %160 = add nsw i32 %mul20.i.i, %51
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds float, float* %8, i64 %161
  %163 = bitcast float* %162 to <8 x float>*
  %wide.load29.1 = load <8 x float>, <8 x float>* %163, align 4, !tbaa !12, !llvm.access.group !16
  %164 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load29.1, <8 x float> <float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000>, <8 x float> %159)
  %165 = add nsw i32 %53, %mul20.i.i
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds float, float* %8, i64 %166
  %168 = bitcast float* %167 to <8 x float>*
  %wide.load30.1 = load <8 x float>, <8 x float>* %168, align 4, !tbaa !12, !llvm.access.group !16
  %169 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load30.1, <8 x float> <float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000>, <8 x float> %164)
  %170 = add nsw i32 %52, %mul41.i.i
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds float, float* %8, i64 %171
  %173 = bitcast float* %172 to <8 x float>*
  %wide.load31.1 = load <8 x float>, <8 x float>* %173, align 4, !tbaa !12, !llvm.access.group !16
  %174 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load31.1, <8 x float> <float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000>, <8 x float> %169)
  %175 = add nsw i32 %mul41.i.i, %51
  %176 = sext i32 %175 to i64
  %177 = getelementptr inbounds float, float* %8, i64 %176
  %178 = bitcast float* %177 to <8 x float>*
  %wide.load32.1 = load <8 x float>, <8 x float>* %178, align 4, !tbaa !12, !llvm.access.group !16
  %179 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load32.1, <8 x float> <float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000>, <8 x float> %174)
  %180 = add nsw i32 %53, %mul41.i.i
  %181 = sext i32 %180 to i64
  %182 = getelementptr inbounds float, float* %8, i64 %181
  %183 = bitcast float* %182 to <8 x float>*
  %wide.load33.1 = load <8 x float>, <8 x float>* %183, align 4, !tbaa !12, !llvm.access.group !16
  %184 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load33.1, <8 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <8 x float> %179)
  %185 = getelementptr inbounds float, float* %12, i64 %161
  %186 = bitcast float* %185 to <8 x float>*
  store <8 x float> %184, <8 x float>* %186, align 4, !tbaa !12, !llvm.access.group !16
  %187 = add nsw i32 %56, %mul.i.i
  %188 = sext i32 %187 to i64
  %189 = getelementptr inbounds float, float* %8, i64 %188
  %190 = bitcast float* %189 to <8 x float>*
  %wide.load.2 = load <8 x float>, <8 x float>* %190, align 4, !tbaa !12, !llvm.access.group !16
  %191 = add nsw i32 %mul.i.i, %55
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds float, float* %8, i64 %192
  %194 = bitcast float* %193 to <8 x float>*
  %wide.load26.2 = load <8 x float>, <8 x float>* %194, align 4, !tbaa !12, !llvm.access.group !16
  %195 = fmul <8 x float> %wide.load26.2, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %196 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load.2, <8 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>, <8 x float> %195)
  %197 = add nsw i32 %57, %mul.i.i
  %198 = sext i32 %197 to i64
  %199 = getelementptr inbounds float, float* %8, i64 %198
  %200 = bitcast float* %199 to <8 x float>*
  %wide.load27.2 = load <8 x float>, <8 x float>* %200, align 4, !tbaa !12, !llvm.access.group !16
  %201 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load27.2, <8 x float> <float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000>, <8 x float> %196)
  %202 = add nsw i32 %56, %mul20.i.i
  %203 = sext i32 %202 to i64
  %204 = getelementptr inbounds float, float* %8, i64 %203
  %205 = bitcast float* %204 to <8 x float>*
  %wide.load28.2 = load <8 x float>, <8 x float>* %205, align 4, !tbaa !12, !llvm.access.group !16
  %206 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load28.2, <8 x float> <float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000>, <8 x float> %201)
  %207 = add nsw i32 %mul20.i.i, %55
  %208 = sext i32 %207 to i64
  %209 = getelementptr inbounds float, float* %8, i64 %208
  %210 = bitcast float* %209 to <8 x float>*
  %wide.load29.2 = load <8 x float>, <8 x float>* %210, align 4, !tbaa !12, !llvm.access.group !16
  %211 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load29.2, <8 x float> <float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000>, <8 x float> %206)
  %212 = add nsw i32 %57, %mul20.i.i
  %213 = sext i32 %212 to i64
  %214 = getelementptr inbounds float, float* %8, i64 %213
  %215 = bitcast float* %214 to <8 x float>*
  %wide.load30.2 = load <8 x float>, <8 x float>* %215, align 4, !tbaa !12, !llvm.access.group !16
  %216 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load30.2, <8 x float> <float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000>, <8 x float> %211)
  %217 = add nsw i32 %56, %mul41.i.i
  %218 = sext i32 %217 to i64
  %219 = getelementptr inbounds float, float* %8, i64 %218
  %220 = bitcast float* %219 to <8 x float>*
  %wide.load31.2 = load <8 x float>, <8 x float>* %220, align 4, !tbaa !12, !llvm.access.group !16
  %221 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load31.2, <8 x float> <float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000>, <8 x float> %216)
  %222 = add nsw i32 %mul41.i.i, %55
  %223 = sext i32 %222 to i64
  %224 = getelementptr inbounds float, float* %8, i64 %223
  %225 = bitcast float* %224 to <8 x float>*
  %wide.load32.2 = load <8 x float>, <8 x float>* %225, align 4, !tbaa !12, !llvm.access.group !16
  %226 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load32.2, <8 x float> <float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000>, <8 x float> %221)
  %227 = add nsw i32 %57, %mul41.i.i
  %228 = sext i32 %227 to i64
  %229 = getelementptr inbounds float, float* %8, i64 %228
  %230 = bitcast float* %229 to <8 x float>*
  %wide.load33.2 = load <8 x float>, <8 x float>* %230, align 4, !tbaa !12, !llvm.access.group !16
  %231 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load33.2, <8 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <8 x float> %226)
  %232 = getelementptr inbounds float, float* %12, i64 %208
  %233 = bitcast float* %232 to <8 x float>*
  store <8 x float> %231, <8 x float>* %233, align 4, !tbaa !12, !llvm.access.group !16
  %234 = add nsw i32 %60, %mul.i.i
  %235 = sext i32 %234 to i64
  %236 = getelementptr inbounds float, float* %8, i64 %235
  %237 = bitcast float* %236 to <8 x float>*
  %wide.load.3 = load <8 x float>, <8 x float>* %237, align 4, !tbaa !12, !llvm.access.group !16
  %238 = add nsw i32 %mul.i.i, %59
  %239 = sext i32 %238 to i64
  %240 = getelementptr inbounds float, float* %8, i64 %239
  %241 = bitcast float* %240 to <8 x float>*
  %wide.load26.3 = load <8 x float>, <8 x float>* %241, align 4, !tbaa !12, !llvm.access.group !16
  %242 = fmul <8 x float> %wide.load26.3, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %243 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load.3, <8 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>, <8 x float> %242)
  %244 = add nsw i32 %61, %mul.i.i
  %245 = sext i32 %244 to i64
  %246 = getelementptr inbounds float, float* %8, i64 %245
  %247 = bitcast float* %246 to <8 x float>*
  %wide.load27.3 = load <8 x float>, <8 x float>* %247, align 4, !tbaa !12, !llvm.access.group !16
  %248 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load27.3, <8 x float> <float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000>, <8 x float> %243)
  %249 = add nsw i32 %60, %mul20.i.i
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds float, float* %8, i64 %250
  %252 = bitcast float* %251 to <8 x float>*
  %wide.load28.3 = load <8 x float>, <8 x float>* %252, align 4, !tbaa !12, !llvm.access.group !16
  %253 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load28.3, <8 x float> <float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000>, <8 x float> %248)
  %254 = add nsw i32 %mul20.i.i, %59
  %255 = sext i32 %254 to i64
  %256 = getelementptr inbounds float, float* %8, i64 %255
  %257 = bitcast float* %256 to <8 x float>*
  %wide.load29.3 = load <8 x float>, <8 x float>* %257, align 4, !tbaa !12, !llvm.access.group !16
  %258 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load29.3, <8 x float> <float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000>, <8 x float> %253)
  %259 = add nsw i32 %61, %mul20.i.i
  %260 = sext i32 %259 to i64
  %261 = getelementptr inbounds float, float* %8, i64 %260
  %262 = bitcast float* %261 to <8 x float>*
  %wide.load30.3 = load <8 x float>, <8 x float>* %262, align 4, !tbaa !12, !llvm.access.group !16
  %263 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load30.3, <8 x float> <float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000>, <8 x float> %258)
  %264 = add nsw i32 %60, %mul41.i.i
  %265 = sext i32 %264 to i64
  %266 = getelementptr inbounds float, float* %8, i64 %265
  %267 = bitcast float* %266 to <8 x float>*
  %wide.load31.3 = load <8 x float>, <8 x float>* %267, align 4, !tbaa !12, !llvm.access.group !16
  %268 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load31.3, <8 x float> <float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000>, <8 x float> %263)
  %269 = add nsw i32 %mul41.i.i, %59
  %270 = sext i32 %269 to i64
  %271 = getelementptr inbounds float, float* %8, i64 %270
  %272 = bitcast float* %271 to <8 x float>*
  %wide.load32.3 = load <8 x float>, <8 x float>* %272, align 4, !tbaa !12, !llvm.access.group !16
  %273 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load32.3, <8 x float> <float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000>, <8 x float> %268)
  %274 = add nsw i32 %61, %mul41.i.i
  %275 = sext i32 %274 to i64
  %276 = getelementptr inbounds float, float* %8, i64 %275
  %277 = bitcast float* %276 to <8 x float>*
  %wide.load33.3 = load <8 x float>, <8 x float>* %277, align 4, !tbaa !12, !llvm.access.group !16
  %278 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load33.3, <8 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <8 x float> %273)
  %279 = getelementptr inbounds float, float* %12, i64 %255
  %280 = bitcast float* %279 to <8 x float>*
  store <8 x float> %278, <8 x float>* %280, align 4, !tbaa !12, !llvm.access.group !16
  br label %pregion_for_end.i.i

pregion_for_end.i.i.loopexit:                     ; preds = %pregion_for_entry.entry.i.i
  br label %pregion_for_end.i.i

pregion_for_end.i.i:                              ; preds = %pregion_for_end.i.i.loopexit, %vector.body
  %281 = add nuw nsw i64 %_local_id_y.i.0, 1
  %exitcond1.not = icmp eq i64 %281, 8
  br i1 %exitcond1.not, label %_pocl_kernel_Convolution2D_kernel.exit, label %pregion_for_entry.pregion_for_init.i.i, !llvm.loop !19

pregion_for_entry.entry.i.i:                      ; preds = %pregion_for_entry.entry.i.i, %pregion_for_entry.entry.i.i.preheader
  %_local_id_x.i.0 = phi i64 [ %299, %pregion_for_entry.entry.i.i ], [ 0, %pregion_for_entry.entry.i.i.preheader ]
  %add1.i.i.i = add nuw nsw i64 %_local_id_x.i.0, %mul.i.i.i
  %conv.i.i = trunc i64 %add1.i.i.i to i32
  %sub3.i.i = add nsw i32 %conv.i.i, -1
  %add.i.i = add nsw i32 %sub3.i.i, %mul.i.i
  %idxprom.i.i = sext i32 %add.i.i to i64
  %arrayidx.i.i = getelementptr inbounds float, float* %8, i64 %idxprom.i.i
  %282 = load float, float* %arrayidx.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %add8.i.i = add nsw i32 %mul.i.i, %conv.i.i
  %idxprom9.i.i = sext i32 %add8.i.i to i64
  %arrayidx10.i.i = getelementptr inbounds float, float* %8, i64 %idxprom9.i.i
  %283 = load float, float* %arrayidx10.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %mul11.i.i = fmul float %283, 5.000000e-01
  %284 = tail call float @llvm.fmuladd.f32(float %282, float 0x3FC99999A0000000, float %mul11.i.i) #4
  %add14.i.i = add nsw i32 %conv.i.i, 1
  %add15.i.i = add nsw i32 %add14.i.i, %mul.i.i
  %idxprom16.i.i = sext i32 %add15.i.i to i64
  %arrayidx17.i.i = getelementptr inbounds float, float* %8, i64 %idxprom16.i.i
  %285 = load float, float* %arrayidx17.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %286 = tail call float @llvm.fmuladd.f32(float %285, float 0xBFE99999A0000000, float %284) #4
  %add22.i.i = add nsw i32 %sub3.i.i, %mul20.i.i
  %idxprom23.i.i = sext i32 %add22.i.i to i64
  %arrayidx24.i.i = getelementptr inbounds float, float* %8, i64 %idxprom23.i.i
  %287 = load float, float* %arrayidx24.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %288 = tail call float @llvm.fmuladd.f32(float %287, float 0xBFD3333340000000, float %286) #4
  %add29.i.i = add nsw i32 %mul20.i.i, %conv.i.i
  %idxprom30.i.i = sext i32 %add29.i.i to i64
  %arrayidx31.i.i = getelementptr inbounds float, float* %8, i64 %idxprom30.i.i
  %289 = load float, float* %arrayidx31.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %290 = tail call float @llvm.fmuladd.f32(float %289, float 0x3FE3333340000000, float %288) #4
  %add36.i.i = add nsw i32 %add14.i.i, %mul20.i.i
  %idxprom37.i.i = sext i32 %add36.i.i to i64
  %arrayidx38.i.i = getelementptr inbounds float, float* %8, i64 %idxprom37.i.i
  %291 = load float, float* %arrayidx38.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %292 = tail call float @llvm.fmuladd.f32(float %291, float 0xBFECCCCCC0000000, float %290) #4
  %add43.i.i = add nsw i32 %sub3.i.i, %mul41.i.i
  %idxprom44.i.i = sext i32 %add43.i.i to i64
  %arrayidx45.i.i = getelementptr inbounds float, float* %8, i64 %idxprom44.i.i
  %293 = load float, float* %arrayidx45.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %294 = tail call float @llvm.fmuladd.f32(float %293, float 0x3FD99999A0000000, float %292) #4
  %add50.i.i = add nsw i32 %mul41.i.i, %conv.i.i
  %idxprom51.i.i = sext i32 %add50.i.i to i64
  %arrayidx52.i.i = getelementptr inbounds float, float* %8, i64 %idxprom51.i.i
  %295 = load float, float* %arrayidx52.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %296 = tail call float @llvm.fmuladd.f32(float %295, float 0x3FE6666660000000, float %294) #4
  %add57.i.i = add nsw i32 %add14.i.i, %mul41.i.i
  %idxprom58.i.i = sext i32 %add57.i.i to i64
  %arrayidx59.i.i = getelementptr inbounds float, float* %8, i64 %idxprom58.i.i
  %297 = load float, float* %arrayidx59.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %298 = tail call float @llvm.fmuladd.f32(float %297, float 0x3FB99999A0000000, float %296) #4
  %arrayidx64.i.i = getelementptr inbounds float, float* %12, i64 %idxprom30.i.i
  store float %298, float* %arrayidx64.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %299 = add nuw nsw i64 %_local_id_x.i.0, 1
  %exitcond.not = icmp eq i64 %299, 32
  br i1 %exitcond.not, label %pregion_for_end.i.i.loopexit, label %pregion_for_entry.entry.i.i, !llvm.loop !24

_pocl_kernel_Convolution2D_kernel.exit:           ; preds = %pregion_for_end.i.i
  ret void
}

; Function Attrs: nofree nounwind
define void @_pocl_kernel_Convolution2D_kernel_workgroup_fast(i8** nocapture readonly %0, { [3 x i64], [3 x i64], [3 x i64], i8*, i32*, i32, i32 }* nocapture readnone %1, i64 %2, i64 %3, i64 %4) local_unnamed_addr #2 {
  %6 = bitcast i8** %0 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr i8*, i8** %0, i64 1
  %9 = bitcast i8** %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr i8*, i8** %0, i64 3
  %12 = bitcast i8** %11 to i32**
  %13 = load i32*, i32** %12, align 8
  %14 = load i32, i32* %13, align 4
  %mul.i.i.i = shl i64 %2, 5
  %mul3.i.i.i = shl i64 %3, 3
  %15 = trunc i64 %3 to i32
  %16 = shl i32 %15, 3
  %17 = add nsw i32 %16, -1
  %18 = mul i32 %14, %17
  %19 = trunc i64 %2 to i32
  %20 = shl i32 %19, 5
  %21 = add i32 %18, %20
  %22 = add i32 %21, -1
  %23 = zext i32 %14 to i64
  %24 = zext i32 %18 to i64
  %25 = sext i32 %20 to i64
  %26 = add nsw i64 %24, %25
  %27 = add i32 %18, %20
  %28 = add i32 %27, 1
  %29 = mul i32 %14, %15
  %30 = shl i32 %29, 3
  %31 = add i32 %30, %20
  %32 = add i32 %31, -8
  %33 = or i32 %32, 7
  %34 = zext i32 %30 to i64
  %35 = add nsw i64 %34, %25
  %36 = add nsw i32 %30, %20
  %37 = or i32 %36, 1
  %38 = or i32 %16, 1
  %39 = mul i32 %14, %38
  %40 = add i32 %39, %20
  %41 = add i32 %40, -1
  %42 = zext i32 %39 to i64
  %43 = add nsw i64 %42, %25
  %44 = add i32 %40, 1
  %45 = trunc i64 %mul.i.i.i to i32
  %46 = add nsw i32 %45, -1
  %47 = or i32 %45, 1
  %48 = trunc i64 %mul.i.i.i to i32
  %49 = or i32 %48, 8
  %50 = add nsw i32 %49, -1
  %51 = or i32 %48, 9
  %52 = trunc i64 %mul.i.i.i to i32
  %53 = or i32 %52, 16
  %54 = add nsw i32 %53, -1
  %55 = or i32 %52, 17
  %56 = trunc i64 %mul.i.i.i to i32
  %57 = or i32 %56, 24
  %58 = add nsw i32 %57, -1
  %59 = or i32 %56, 25
  br label %pregion_for_entry.pregion_for_init.i.i

pregion_for_entry.pregion_for_init.i.i:           ; preds = %pregion_for_end.i.i, %5
  %_local_id_y.i.0 = phi i64 [ 0, %5 ], [ %279, %pregion_for_end.i.i ]
  %60 = mul i64 %_local_id_y.i.0, %23
  %add6.i.i.i = add nuw nsw i64 %_local_id_y.i.0, %mul3.i.i.i
  %conv2.i.i = trunc i64 %add6.i.i.i to i32
  %sub.i.i = add nsw i32 %conv2.i.i, -1
  %mul.i.i = mul nsw i32 %sub.i.i, %14
  %mul20.i.i = mul nsw i32 %14, %conv2.i.i
  %add40.i.i = add nsw i32 %conv2.i.i, 1
  %mul41.i.i = mul nsw i32 %add40.i.i, %14
  %61 = trunc i64 %60 to i32
  %62 = add i32 %44, %61
  %63 = add i64 %43, %60
  %64 = trunc i64 %63 to i32
  %65 = trunc i64 %60 to i32
  %66 = add i32 %41, %65
  %67 = trunc i64 %60 to i32
  %68 = add i32 %37, %67
  %69 = add i64 %35, %60
  %70 = trunc i64 %69 to i32
  %71 = trunc i64 %60 to i32
  %72 = add i32 %33, %71
  %73 = trunc i64 %60 to i32
  %74 = add i32 %28, %73
  %75 = add i64 %26, %60
  %76 = trunc i64 %75 to i32
  %77 = trunc i64 %60 to i32
  %78 = add i32 %22, %77
  %79 = insertelement <8 x i32> undef, i32 %78, i32 0
  %80 = insertelement <8 x i32> %79, i32 %76, i32 1
  %81 = insertelement <8 x i32> %80, i32 %74, i32 2
  %82 = insertelement <8 x i32> %81, i32 %72, i32 3
  %83 = insertelement <8 x i32> %82, i32 %70, i32 4
  %84 = insertelement <8 x i32> %83, i32 %68, i32 5
  %85 = insertelement <8 x i32> %84, i32 %66, i32 6
  %86 = insertelement <8 x i32> %85, i32 %64, i32 7
  %87 = icmp sgt <8 x i32> %86, <i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616, i32 2147483616>
  %88 = icmp sgt i32 %62, 2147483616
  %89 = call i1 @llvm.experimental.vector.reduce.or.v8i1(<8 x i1> %87)
  %90 = or i1 %89, %88
  br i1 %90, label %pregion_for_entry.entry.i.i.preheader, label %vector.body

pregion_for_entry.entry.i.i.preheader:            ; preds = %pregion_for_entry.pregion_for_init.i.i
  br label %pregion_for_entry.entry.i.i

vector.body:                                      ; preds = %pregion_for_entry.pregion_for_init.i.i
  %91 = add nsw i32 %46, %mul.i.i
  %92 = sext i32 %91 to i64
  %93 = getelementptr inbounds float, float* %7, i64 %92
  %94 = bitcast float* %93 to <8 x float>*
  %wide.load = load <8 x float>, <8 x float>* %94, align 4, !tbaa !12, !llvm.access.group !16
  %95 = add nsw i32 %mul.i.i, %45
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds float, float* %7, i64 %96
  %98 = bitcast float* %97 to <8 x float>*
  %wide.load26 = load <8 x float>, <8 x float>* %98, align 4, !tbaa !12, !llvm.access.group !16
  %99 = fmul <8 x float> %wide.load26, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %100 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load, <8 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>, <8 x float> %99)
  %101 = add nsw i32 %47, %mul.i.i
  %102 = sext i32 %101 to i64
  %103 = getelementptr inbounds float, float* %7, i64 %102
  %104 = bitcast float* %103 to <8 x float>*
  %wide.load27 = load <8 x float>, <8 x float>* %104, align 4, !tbaa !12, !llvm.access.group !16
  %105 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load27, <8 x float> <float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000>, <8 x float> %100)
  %106 = add nsw i32 %46, %mul20.i.i
  %107 = sext i32 %106 to i64
  %108 = getelementptr inbounds float, float* %7, i64 %107
  %109 = bitcast float* %108 to <8 x float>*
  %wide.load28 = load <8 x float>, <8 x float>* %109, align 4, !tbaa !12, !llvm.access.group !16
  %110 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load28, <8 x float> <float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000>, <8 x float> %105)
  %111 = add nsw i32 %mul20.i.i, %45
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds float, float* %7, i64 %112
  %114 = bitcast float* %113 to <8 x float>*
  %wide.load29 = load <8 x float>, <8 x float>* %114, align 4, !tbaa !12, !llvm.access.group !16
  %115 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load29, <8 x float> <float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000>, <8 x float> %110)
  %116 = add nsw i32 %47, %mul20.i.i
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds float, float* %7, i64 %117
  %119 = bitcast float* %118 to <8 x float>*
  %wide.load30 = load <8 x float>, <8 x float>* %119, align 4, !tbaa !12, !llvm.access.group !16
  %120 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load30, <8 x float> <float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000>, <8 x float> %115)
  %121 = add nsw i32 %46, %mul41.i.i
  %122 = sext i32 %121 to i64
  %123 = getelementptr inbounds float, float* %7, i64 %122
  %124 = bitcast float* %123 to <8 x float>*
  %wide.load31 = load <8 x float>, <8 x float>* %124, align 4, !tbaa !12, !llvm.access.group !16
  %125 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load31, <8 x float> <float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000>, <8 x float> %120)
  %126 = add nsw i32 %mul41.i.i, %45
  %127 = sext i32 %126 to i64
  %128 = getelementptr inbounds float, float* %7, i64 %127
  %129 = bitcast float* %128 to <8 x float>*
  %wide.load32 = load <8 x float>, <8 x float>* %129, align 4, !tbaa !12, !llvm.access.group !16
  %130 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load32, <8 x float> <float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000>, <8 x float> %125)
  %131 = add nsw i32 %47, %mul41.i.i
  %132 = sext i32 %131 to i64
  %133 = getelementptr inbounds float, float* %7, i64 %132
  %134 = bitcast float* %133 to <8 x float>*
  %wide.load33 = load <8 x float>, <8 x float>* %134, align 4, !tbaa !12, !llvm.access.group !16
  %135 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load33, <8 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <8 x float> %130)
  %136 = getelementptr inbounds float, float* %10, i64 %112
  %137 = bitcast float* %136 to <8 x float>*
  store <8 x float> %135, <8 x float>* %137, align 4, !tbaa !12, !llvm.access.group !16
  %138 = add nsw i32 %50, %mul.i.i
  %139 = sext i32 %138 to i64
  %140 = getelementptr inbounds float, float* %7, i64 %139
  %141 = bitcast float* %140 to <8 x float>*
  %wide.load.1 = load <8 x float>, <8 x float>* %141, align 4, !tbaa !12, !llvm.access.group !16
  %142 = add nsw i32 %mul.i.i, %49
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds float, float* %7, i64 %143
  %145 = bitcast float* %144 to <8 x float>*
  %wide.load26.1 = load <8 x float>, <8 x float>* %145, align 4, !tbaa !12, !llvm.access.group !16
  %146 = fmul <8 x float> %wide.load26.1, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %147 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load.1, <8 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>, <8 x float> %146)
  %148 = add nsw i32 %51, %mul.i.i
  %149 = sext i32 %148 to i64
  %150 = getelementptr inbounds float, float* %7, i64 %149
  %151 = bitcast float* %150 to <8 x float>*
  %wide.load27.1 = load <8 x float>, <8 x float>* %151, align 4, !tbaa !12, !llvm.access.group !16
  %152 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load27.1, <8 x float> <float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000>, <8 x float> %147)
  %153 = add nsw i32 %50, %mul20.i.i
  %154 = sext i32 %153 to i64
  %155 = getelementptr inbounds float, float* %7, i64 %154
  %156 = bitcast float* %155 to <8 x float>*
  %wide.load28.1 = load <8 x float>, <8 x float>* %156, align 4, !tbaa !12, !llvm.access.group !16
  %157 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load28.1, <8 x float> <float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000>, <8 x float> %152)
  %158 = add nsw i32 %mul20.i.i, %49
  %159 = sext i32 %158 to i64
  %160 = getelementptr inbounds float, float* %7, i64 %159
  %161 = bitcast float* %160 to <8 x float>*
  %wide.load29.1 = load <8 x float>, <8 x float>* %161, align 4, !tbaa !12, !llvm.access.group !16
  %162 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load29.1, <8 x float> <float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000>, <8 x float> %157)
  %163 = add nsw i32 %51, %mul20.i.i
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds float, float* %7, i64 %164
  %166 = bitcast float* %165 to <8 x float>*
  %wide.load30.1 = load <8 x float>, <8 x float>* %166, align 4, !tbaa !12, !llvm.access.group !16
  %167 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load30.1, <8 x float> <float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000>, <8 x float> %162)
  %168 = add nsw i32 %50, %mul41.i.i
  %169 = sext i32 %168 to i64
  %170 = getelementptr inbounds float, float* %7, i64 %169
  %171 = bitcast float* %170 to <8 x float>*
  %wide.load31.1 = load <8 x float>, <8 x float>* %171, align 4, !tbaa !12, !llvm.access.group !16
  %172 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load31.1, <8 x float> <float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000>, <8 x float> %167)
  %173 = add nsw i32 %mul41.i.i, %49
  %174 = sext i32 %173 to i64
  %175 = getelementptr inbounds float, float* %7, i64 %174
  %176 = bitcast float* %175 to <8 x float>*
  %wide.load32.1 = load <8 x float>, <8 x float>* %176, align 4, !tbaa !12, !llvm.access.group !16
  %177 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load32.1, <8 x float> <float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000>, <8 x float> %172)
  %178 = add nsw i32 %51, %mul41.i.i
  %179 = sext i32 %178 to i64
  %180 = getelementptr inbounds float, float* %7, i64 %179
  %181 = bitcast float* %180 to <8 x float>*
  %wide.load33.1 = load <8 x float>, <8 x float>* %181, align 4, !tbaa !12, !llvm.access.group !16
  %182 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load33.1, <8 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <8 x float> %177)
  %183 = getelementptr inbounds float, float* %10, i64 %159
  %184 = bitcast float* %183 to <8 x float>*
  store <8 x float> %182, <8 x float>* %184, align 4, !tbaa !12, !llvm.access.group !16
  %185 = add nsw i32 %54, %mul.i.i
  %186 = sext i32 %185 to i64
  %187 = getelementptr inbounds float, float* %7, i64 %186
  %188 = bitcast float* %187 to <8 x float>*
  %wide.load.2 = load <8 x float>, <8 x float>* %188, align 4, !tbaa !12, !llvm.access.group !16
  %189 = add nsw i32 %mul.i.i, %53
  %190 = sext i32 %189 to i64
  %191 = getelementptr inbounds float, float* %7, i64 %190
  %192 = bitcast float* %191 to <8 x float>*
  %wide.load26.2 = load <8 x float>, <8 x float>* %192, align 4, !tbaa !12, !llvm.access.group !16
  %193 = fmul <8 x float> %wide.load26.2, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %194 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load.2, <8 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>, <8 x float> %193)
  %195 = add nsw i32 %55, %mul.i.i
  %196 = sext i32 %195 to i64
  %197 = getelementptr inbounds float, float* %7, i64 %196
  %198 = bitcast float* %197 to <8 x float>*
  %wide.load27.2 = load <8 x float>, <8 x float>* %198, align 4, !tbaa !12, !llvm.access.group !16
  %199 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load27.2, <8 x float> <float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000>, <8 x float> %194)
  %200 = add nsw i32 %54, %mul20.i.i
  %201 = sext i32 %200 to i64
  %202 = getelementptr inbounds float, float* %7, i64 %201
  %203 = bitcast float* %202 to <8 x float>*
  %wide.load28.2 = load <8 x float>, <8 x float>* %203, align 4, !tbaa !12, !llvm.access.group !16
  %204 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load28.2, <8 x float> <float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000>, <8 x float> %199)
  %205 = add nsw i32 %mul20.i.i, %53
  %206 = sext i32 %205 to i64
  %207 = getelementptr inbounds float, float* %7, i64 %206
  %208 = bitcast float* %207 to <8 x float>*
  %wide.load29.2 = load <8 x float>, <8 x float>* %208, align 4, !tbaa !12, !llvm.access.group !16
  %209 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load29.2, <8 x float> <float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000>, <8 x float> %204)
  %210 = add nsw i32 %55, %mul20.i.i
  %211 = sext i32 %210 to i64
  %212 = getelementptr inbounds float, float* %7, i64 %211
  %213 = bitcast float* %212 to <8 x float>*
  %wide.load30.2 = load <8 x float>, <8 x float>* %213, align 4, !tbaa !12, !llvm.access.group !16
  %214 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load30.2, <8 x float> <float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000>, <8 x float> %209)
  %215 = add nsw i32 %54, %mul41.i.i
  %216 = sext i32 %215 to i64
  %217 = getelementptr inbounds float, float* %7, i64 %216
  %218 = bitcast float* %217 to <8 x float>*
  %wide.load31.2 = load <8 x float>, <8 x float>* %218, align 4, !tbaa !12, !llvm.access.group !16
  %219 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load31.2, <8 x float> <float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000>, <8 x float> %214)
  %220 = add nsw i32 %mul41.i.i, %53
  %221 = sext i32 %220 to i64
  %222 = getelementptr inbounds float, float* %7, i64 %221
  %223 = bitcast float* %222 to <8 x float>*
  %wide.load32.2 = load <8 x float>, <8 x float>* %223, align 4, !tbaa !12, !llvm.access.group !16
  %224 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load32.2, <8 x float> <float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000>, <8 x float> %219)
  %225 = add nsw i32 %55, %mul41.i.i
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds float, float* %7, i64 %226
  %228 = bitcast float* %227 to <8 x float>*
  %wide.load33.2 = load <8 x float>, <8 x float>* %228, align 4, !tbaa !12, !llvm.access.group !16
  %229 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load33.2, <8 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <8 x float> %224)
  %230 = getelementptr inbounds float, float* %10, i64 %206
  %231 = bitcast float* %230 to <8 x float>*
  store <8 x float> %229, <8 x float>* %231, align 4, !tbaa !12, !llvm.access.group !16
  %232 = add nsw i32 %58, %mul.i.i
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds float, float* %7, i64 %233
  %235 = bitcast float* %234 to <8 x float>*
  %wide.load.3 = load <8 x float>, <8 x float>* %235, align 4, !tbaa !12, !llvm.access.group !16
  %236 = add nsw i32 %mul.i.i, %57
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds float, float* %7, i64 %237
  %239 = bitcast float* %238 to <8 x float>*
  %wide.load26.3 = load <8 x float>, <8 x float>* %239, align 4, !tbaa !12, !llvm.access.group !16
  %240 = fmul <8 x float> %wide.load26.3, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %241 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load.3, <8 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>, <8 x float> %240)
  %242 = add nsw i32 %59, %mul.i.i
  %243 = sext i32 %242 to i64
  %244 = getelementptr inbounds float, float* %7, i64 %243
  %245 = bitcast float* %244 to <8 x float>*
  %wide.load27.3 = load <8 x float>, <8 x float>* %245, align 4, !tbaa !12, !llvm.access.group !16
  %246 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load27.3, <8 x float> <float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000, float 0xBFE99999A0000000>, <8 x float> %241)
  %247 = add nsw i32 %58, %mul20.i.i
  %248 = sext i32 %247 to i64
  %249 = getelementptr inbounds float, float* %7, i64 %248
  %250 = bitcast float* %249 to <8 x float>*
  %wide.load28.3 = load <8 x float>, <8 x float>* %250, align 4, !tbaa !12, !llvm.access.group !16
  %251 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load28.3, <8 x float> <float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000, float 0xBFD3333340000000>, <8 x float> %246)
  %252 = add nsw i32 %mul20.i.i, %57
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds float, float* %7, i64 %253
  %255 = bitcast float* %254 to <8 x float>*
  %wide.load29.3 = load <8 x float>, <8 x float>* %255, align 4, !tbaa !12, !llvm.access.group !16
  %256 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load29.3, <8 x float> <float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000, float 0x3FE3333340000000>, <8 x float> %251)
  %257 = add nsw i32 %59, %mul20.i.i
  %258 = sext i32 %257 to i64
  %259 = getelementptr inbounds float, float* %7, i64 %258
  %260 = bitcast float* %259 to <8 x float>*
  %wide.load30.3 = load <8 x float>, <8 x float>* %260, align 4, !tbaa !12, !llvm.access.group !16
  %261 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load30.3, <8 x float> <float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000, float 0xBFECCCCCC0000000>, <8 x float> %256)
  %262 = add nsw i32 %58, %mul41.i.i
  %263 = sext i32 %262 to i64
  %264 = getelementptr inbounds float, float* %7, i64 %263
  %265 = bitcast float* %264 to <8 x float>*
  %wide.load31.3 = load <8 x float>, <8 x float>* %265, align 4, !tbaa !12, !llvm.access.group !16
  %266 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load31.3, <8 x float> <float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000, float 0x3FD99999A0000000>, <8 x float> %261)
  %267 = add nsw i32 %mul41.i.i, %57
  %268 = sext i32 %267 to i64
  %269 = getelementptr inbounds float, float* %7, i64 %268
  %270 = bitcast float* %269 to <8 x float>*
  %wide.load32.3 = load <8 x float>, <8 x float>* %270, align 4, !tbaa !12, !llvm.access.group !16
  %271 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load32.3, <8 x float> <float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000, float 0x3FE6666660000000>, <8 x float> %266)
  %272 = add nsw i32 %59, %mul41.i.i
  %273 = sext i32 %272 to i64
  %274 = getelementptr inbounds float, float* %7, i64 %273
  %275 = bitcast float* %274 to <8 x float>*
  %wide.load33.3 = load <8 x float>, <8 x float>* %275, align 4, !tbaa !12, !llvm.access.group !16
  %276 = call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %wide.load33.3, <8 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <8 x float> %271)
  %277 = getelementptr inbounds float, float* %10, i64 %253
  %278 = bitcast float* %277 to <8 x float>*
  store <8 x float> %276, <8 x float>* %278, align 4, !tbaa !12, !llvm.access.group !16
  br label %pregion_for_end.i.i

pregion_for_end.i.i.loopexit:                     ; preds = %pregion_for_entry.entry.i.i
  br label %pregion_for_end.i.i

pregion_for_end.i.i:                              ; preds = %pregion_for_end.i.i.loopexit, %vector.body
  %279 = add nuw nsw i64 %_local_id_y.i.0, 1
  %exitcond1.not = icmp eq i64 %279, 8
  br i1 %exitcond1.not, label %_pocl_kernel_Convolution2D_kernel.exit, label %pregion_for_entry.pregion_for_init.i.i, !llvm.loop !19

pregion_for_entry.entry.i.i:                      ; preds = %pregion_for_entry.entry.i.i, %pregion_for_entry.entry.i.i.preheader
  %_local_id_x.i.0 = phi i64 [ %297, %pregion_for_entry.entry.i.i ], [ 0, %pregion_for_entry.entry.i.i.preheader ]
  %add1.i.i.i = add nuw nsw i64 %_local_id_x.i.0, %mul.i.i.i
  %conv.i.i = trunc i64 %add1.i.i.i to i32
  %sub3.i.i = add nsw i32 %conv.i.i, -1
  %add.i.i = add nsw i32 %sub3.i.i, %mul.i.i
  %idxprom.i.i = sext i32 %add.i.i to i64
  %arrayidx.i.i = getelementptr inbounds float, float* %7, i64 %idxprom.i.i
  %280 = load float, float* %arrayidx.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %add8.i.i = add nsw i32 %mul.i.i, %conv.i.i
  %idxprom9.i.i = sext i32 %add8.i.i to i64
  %arrayidx10.i.i = getelementptr inbounds float, float* %7, i64 %idxprom9.i.i
  %281 = load float, float* %arrayidx10.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %mul11.i.i = fmul float %281, 5.000000e-01
  %282 = tail call float @llvm.fmuladd.f32(float %280, float 0x3FC99999A0000000, float %mul11.i.i) #4
  %add14.i.i = add nsw i32 %conv.i.i, 1
  %add15.i.i = add nsw i32 %add14.i.i, %mul.i.i
  %idxprom16.i.i = sext i32 %add15.i.i to i64
  %arrayidx17.i.i = getelementptr inbounds float, float* %7, i64 %idxprom16.i.i
  %283 = load float, float* %arrayidx17.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %284 = tail call float @llvm.fmuladd.f32(float %283, float 0xBFE99999A0000000, float %282) #4
  %add22.i.i = add nsw i32 %sub3.i.i, %mul20.i.i
  %idxprom23.i.i = sext i32 %add22.i.i to i64
  %arrayidx24.i.i = getelementptr inbounds float, float* %7, i64 %idxprom23.i.i
  %285 = load float, float* %arrayidx24.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %286 = tail call float @llvm.fmuladd.f32(float %285, float 0xBFD3333340000000, float %284) #4
  %add29.i.i = add nsw i32 %mul20.i.i, %conv.i.i
  %idxprom30.i.i = sext i32 %add29.i.i to i64
  %arrayidx31.i.i = getelementptr inbounds float, float* %7, i64 %idxprom30.i.i
  %287 = load float, float* %arrayidx31.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %288 = tail call float @llvm.fmuladd.f32(float %287, float 0x3FE3333340000000, float %286) #4
  %add36.i.i = add nsw i32 %add14.i.i, %mul20.i.i
  %idxprom37.i.i = sext i32 %add36.i.i to i64
  %arrayidx38.i.i = getelementptr inbounds float, float* %7, i64 %idxprom37.i.i
  %289 = load float, float* %arrayidx38.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %290 = tail call float @llvm.fmuladd.f32(float %289, float 0xBFECCCCCC0000000, float %288) #4
  %add43.i.i = add nsw i32 %sub3.i.i, %mul41.i.i
  %idxprom44.i.i = sext i32 %add43.i.i to i64
  %arrayidx45.i.i = getelementptr inbounds float, float* %7, i64 %idxprom44.i.i
  %291 = load float, float* %arrayidx45.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %292 = tail call float @llvm.fmuladd.f32(float %291, float 0x3FD99999A0000000, float %290) #4
  %add50.i.i = add nsw i32 %mul41.i.i, %conv.i.i
  %idxprom51.i.i = sext i32 %add50.i.i to i64
  %arrayidx52.i.i = getelementptr inbounds float, float* %7, i64 %idxprom51.i.i
  %293 = load float, float* %arrayidx52.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %294 = tail call float @llvm.fmuladd.f32(float %293, float 0x3FE6666660000000, float %292) #4
  %add57.i.i = add nsw i32 %add14.i.i, %mul41.i.i
  %idxprom58.i.i = sext i32 %add57.i.i to i64
  %arrayidx59.i.i = getelementptr inbounds float, float* %7, i64 %idxprom58.i.i
  %295 = load float, float* %arrayidx59.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %296 = tail call float @llvm.fmuladd.f32(float %295, float 0x3FB99999A0000000, float %294) #4
  %arrayidx64.i.i = getelementptr inbounds float, float* %10, i64 %idxprom30.i.i
  store float %296, float* %arrayidx64.i.i, align 4, !tbaa !12, !llvm.access.group !16
  %297 = add nuw nsw i64 %_local_id_x.i.0, 1
  %exitcond.not = icmp eq i64 %297, 32
  br i1 %exitcond.not, label %pregion_for_end.i.i.loopexit, label %pregion_for_entry.entry.i.i, !llvm.loop !25

_pocl_kernel_Convolution2D_kernel.exit:           ; preds = %pregion_for_end.i.i
  ret void
}

; Function Attrs: nounwind readnone speculatable willreturn
declare <8 x float> @llvm.fmuladd.v8f32(<8 x float>, <8 x float>, <8 x float>) #0

; Function Attrs: nounwind readnone willreturn
declare i1 @llvm.experimental.vector.reduce.or.v8i1(<8 x i1>) #3

attributes #0 = { nounwind readnone speculatable willreturn }
attributes #1 = { alwaysinline nofree norecurse nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-builtins" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "stackrealign" "target-cpu"="skylake" "target-features"="+adx,+aes,+avx,+avx2,+bmi,+bmi2,+clflushopt,+cx16,+cx8,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+popcnt,+prfchw,+rdrnd,+rdseed,+sahf,+sgx,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsavec,+xsaveopt,+xsaves" "uniform-work-group-size"="true" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nofree nounwind }
attributes #3 = { nounwind readnone willreturn }
attributes #4 = { nounwind }

!llvm.module.flags = !{!0, !1, !2}
!opencl.ocl.version = !{!3}
!llvm.ident = !{!4}
!opencl.spir.version = !{!3}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 7, !"PIE Level", i32 2}
!3 = !{i32 1, i32 2}
!4 = !{!"clang version 11.0.0 (git@github.com:llvm/llvm-project.git 91e89f9a5115b0f83b8f026e1ad0e6d1f885fa9b)"}
!5 = !{i32 1, i32 1, i32 0, i32 0}
!6 = !{!"none", !"none", !"none", !"none"}
!7 = !{!"DATA_TYPE*", !"DATA_TYPE*", !"int", !"int"}
!8 = !{!"float*", !"float*", !"int", !"int"}
!9 = !{!"", !"", !"", !""}
!10 = !{!"A", !"B", !"ni", !"nj"}
!11 = !{i32 1}
!12 = !{!13, !13, i64 0}
!13 = !{!"float", !14, i64 0}
!14 = !{!"omnipotent char", !15, i64 0}
!15 = !{!"Simple C/C++ TBAA"}
!16 = !{!17, !18}
!17 = distinct !{}
!18 = distinct !{}
!19 = distinct !{!19, !20}
!20 = !{!"llvm.loop.parallel_accesses", !18}
!21 = distinct !{!21, !22, !23}
!22 = !{!"llvm.loop.parallel_accesses", !17}
!23 = !{!"llvm.loop.isvectorized", i32 1}
!24 = distinct !{!24, !22, !23}
!25 = distinct !{!25, !22, !23}
