; ModuleID = './PK/NHAONNAKOLMMJBLNPENBBBCNNPFLDHLMKECDA/runJacobi2D_kernel1/32-8-1-goffs0-smallgrid/parallel.bc'
source_filename = "parallel_bc"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: alwaysinline nofree norecurse nounwind
define void @_pocl_kernel_runJacobi2D_kernel1(float* nocapture readonly %0, float* nocapture %1, i32 %2, { [3 x i64], [3 x i64], [3 x i64], i8*, i32*, i32, i32 }* nocapture readnone %3, i64 %4, i64 %5, i64 %6) local_unnamed_addr #0 !kernel_arg_addr_space !5 !kernel_arg_access_qual !6 !kernel_arg_type !7 !kernel_arg_base_type !8 !kernel_arg_type_qual !9 !kernel_arg_name !10 !pocl_generated !11 {
  %mul3.i.i = shl i64 %5, 3
  %mul.i.i = shl i64 %4, 5
  %sub.i = add nsw i32 %2, -1
  %8 = trunc i64 %5 to i32
  %9 = mul i32 %8, %2
  %10 = shl i32 %9, 3
  %11 = trunc i64 %4 to i32
  %12 = shl i32 %11, 5
  %13 = add i32 %10, %12
  %14 = zext i32 %2 to i64
  %15 = add i32 %13, -8
  %16 = or i32 %15, 7
  %17 = or i32 %13, 1
  %18 = shl i32 %8, 3
  %19 = or i32 %18, 1
  %20 = mul i32 %19, %2
  %21 = add i32 %20, %12
  %22 = add i32 %18, -1
  %23 = mul i32 %22, %2
  %24 = add i32 %23, %12
  %25 = trunc i64 %5 to i32
  %26 = mul i32 %25, %2
  %27 = shl i32 %26, 3
  %28 = trunc i64 %4 to i32
  %29 = shl i32 %28, 5
  %30 = add i32 %27, %29
  %31 = zext i32 %2 to i64
  %scevgep17 = getelementptr float, float* %1, i64 32
  %32 = shl i32 %25, 3
  %33 = add i32 %32, -1
  %34 = mul i32 %33, %2
  %35 = add i32 %34, %29
  %scevgep22 = getelementptr float, float* %0, i64 32
  %36 = or i32 %32, 1
  %37 = mul i32 %36, %2
  %38 = add i32 %37, %29
  %scevgep27 = getelementptr float, float* %0, i64 32
  %39 = or i32 %30, 1
  %40 = zext i32 %39 to i64
  %scevgep32 = getelementptr float, float* %0, i64 32
  %41 = add i32 %27, %29
  %42 = add i32 %41, -8
  %43 = or i32 %42, 7
  %scevgep37 = getelementptr float, float* %0, i64 32
  %scevgep42 = getelementptr float, float* %0, i64 32
  %bound056 = icmp ugt float* %scevgep42, %1
  %bound157 = icmp ugt float* %scevgep17, %0
  %found.conflict58 = and i1 %bound056, %bound157
  %broadcast.splatinsert = insertelement <8 x i64> undef, i64 %mul.i.i, i32 0
  %broadcast.splat = shufflevector <8 x i64> %broadcast.splatinsert, <8 x i64> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert60 = insertelement <8 x i32> undef, i32 %sub.i, i32 0
  %broadcast.splat61 = shufflevector <8 x i32> %broadcast.splatinsert60, <8 x i32> undef, <8 x i32> zeroinitializer
  %44 = trunc <8 x i64> %broadcast.splat to <8 x i32>
  %45 = or <8 x i32> %44, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %46 = icmp sgt <8 x i32> %45, zeroinitializer
  %47 = icmp sgt <8 x i32> %broadcast.splat61, %45
  %48 = and <8 x i1> %47, %46
  %49 = extractelement <8 x i32> %45, i32 0
  %50 = trunc <8 x i64> %broadcast.splat to <8 x i32>
  %51 = or <8 x i32> %50, <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %52 = icmp sgt <8 x i32> %51, zeroinitializer
  %53 = icmp sgt <8 x i32> %broadcast.splat61, %51
  %54 = and <8 x i1> %53, %52
  %55 = extractelement <8 x i32> %51, i32 0
  %56 = trunc <8 x i64> %broadcast.splat to <8 x i32>
  %57 = or <8 x i32> %56, <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %58 = icmp sgt <8 x i32> %57, zeroinitializer
  %59 = icmp sgt <8 x i32> %broadcast.splat61, %57
  %60 = and <8 x i1> %59, %58
  %61 = extractelement <8 x i32> %57, i32 0
  %62 = trunc <8 x i64> %broadcast.splat to <8 x i32>
  %63 = or <8 x i32> %62, <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %64 = icmp sgt <8 x i32> %63, zeroinitializer
  %65 = icmp sgt <8 x i32> %broadcast.splat61, %63
  %66 = and <8 x i1> %65, %64
  %67 = extractelement <8 x i32> %63, i32 0
  br label %pregion_for_entry.pregion_for_init.i

pregion_for_entry.pregion_for_init.i:             ; preds = %pregion_for_end.i, %7
  %_local_id_y.0 = phi i64 [ 0, %7 ], [ %217, %pregion_for_end.i ]
  %68 = mul i64 %_local_id_y.0, %31
  %69 = trunc i64 %68 to i32
  %70 = add i32 %30, %69
  %71 = sext i32 %70 to i64
  %scevgep = getelementptr float, float* %1, i64 %71
  %scevgep18 = getelementptr float, float* %scevgep17, i64 %71
  %72 = trunc i64 %68 to i32
  %73 = add i32 %35, %72
  %74 = sext i32 %73 to i64
  %scevgep20 = getelementptr float, float* %0, i64 %74
  %scevgep23 = getelementptr float, float* %scevgep22, i64 %74
  %75 = trunc i64 %68 to i32
  %76 = add i32 %38, %75
  %77 = sext i32 %76 to i64
  %scevgep25 = getelementptr float, float* %0, i64 %77
  %scevgep28 = getelementptr float, float* %scevgep27, i64 %77
  %78 = add i64 %68, %40
  %sext = shl i64 %78, 32
  %79 = ashr exact i64 %sext, 32
  %scevgep30 = getelementptr float, float* %0, i64 %79
  %scevgep33 = getelementptr float, float* %scevgep32, i64 %79
  %80 = trunc i64 %68 to i32
  %81 = add i32 %43, %80
  %82 = sext i32 %81 to i64
  %scevgep35 = getelementptr float, float* %0, i64 %82
  %scevgep38 = getelementptr float, float* %scevgep37, i64 %82
  %83 = mul i64 %_local_id_y.0, %14
  %add6.i.i = add nuw nsw i64 %_local_id_y.0, %mul3.i.i
  %conv.i = trunc i64 %add6.i.i to i32
  %cmp.i = icmp sgt i32 %conv.i, 0
  %mul.i = mul nsw i32 %conv.i, %2
  %add25.i = add nuw nsw i32 %conv.i, 1
  %mul26.i = mul nsw i32 %add25.i, %2
  %sub31.i = add nsw i32 %conv.i, -1
  %mul32.i = mul nsw i32 %sub31.i, %2
  %cmp4.i = icmp sgt i32 %sub.i, %conv.i
  %or.cond = and i1 %cmp.i, %cmp4.i
  br i1 %or.cond, label %vector.scevcheck, label %pregion_for_end.i

vector.scevcheck:                                 ; preds = %pregion_for_entry.pregion_for_init.i
  %84 = trunc i64 %83 to i32
  %85 = add i32 %24, %84
  %86 = trunc i64 %83 to i32
  %87 = add i32 %21, %86
  %88 = trunc i64 %83 to i32
  %89 = add i32 %17, %88
  %90 = trunc i64 %83 to i32
  %91 = add i32 %16, %90
  %92 = trunc i64 %83 to i32
  %93 = add i32 %13, %92
  %94 = icmp sgt i32 %93, 2147483616
  %95 = icmp sgt i32 %91, 2147483616
  %96 = or i1 %94, %95
  %97 = icmp sgt i32 %89, 2147483616
  %98 = or i1 %96, %97
  %99 = icmp sgt i32 %87, 2147483616
  %100 = or i1 %98, %99
  %101 = icmp sgt i32 %85, 2147483616
  %102 = or i1 %100, %101
  br i1 %102, label %pregion_for_entry.entry.i.us.us.preheader, label %vector.memcheck

pregion_for_entry.entry.i.us.us.preheader:        ; preds = %vector.memcheck, %vector.scevcheck
  br label %pregion_for_entry.entry.i.us.us

vector.memcheck:                                  ; preds = %vector.scevcheck
  %bound0 = icmp ult float* %scevgep, %scevgep23
  %bound1 = icmp ult float* %scevgep20, %scevgep18
  %found.conflict = and i1 %bound0, %bound1
  %bound045 = icmp ult float* %scevgep, %scevgep28
  %bound146 = icmp ult float* %scevgep25, %scevgep18
  %found.conflict47 = and i1 %bound045, %bound146
  %conflict.rdx = or i1 %found.conflict, %found.conflict47
  %bound048 = icmp ult float* %scevgep, %scevgep33
  %bound149 = icmp ult float* %scevgep30, %scevgep18
  %found.conflict50 = and i1 %bound048, %bound149
  %conflict.rdx51 = or i1 %conflict.rdx, %found.conflict50
  %bound052 = icmp ult float* %scevgep, %scevgep38
  %bound153 = icmp ult float* %scevgep35, %scevgep18
  %found.conflict54 = and i1 %bound052, %bound153
  %conflict.rdx55 = or i1 %conflict.rdx51, %found.conflict54
  %conflict.rdx59 = or i1 %conflict.rdx55, %found.conflict58
  br i1 %conflict.rdx59, label %pregion_for_entry.entry.i.us.us.preheader, label %vector.body

vector.body:                                      ; preds = %vector.memcheck
  %103 = add i32 %mul.i, %49
  %104 = sext i32 %103 to i64
  %105 = getelementptr inbounds float, float* %0, i64 %104
  %106 = bitcast float* %105 to <8 x float>*
  %wide.masked.load = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %106, i32 4, <8 x i1> %48, <8 x float> undef), !tbaa !12, !alias.scope !16
  %107 = add i32 %103, -1
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds float, float* %0, i64 %108
  %110 = bitcast float* %109 to <8 x float>*
  %wide.masked.load62 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %110, i32 4, <8 x i1> %48, <8 x float> undef), !tbaa !12, !alias.scope !19
  %111 = fadd <8 x float> %wide.masked.load, %wide.masked.load62
  %112 = add i32 %103, 1
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds float, float* %0, i64 %113
  %115 = bitcast float* %114 to <8 x float>*
  %wide.masked.load63 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %115, i32 4, <8 x i1> %48, <8 x float> undef), !tbaa !12, !alias.scope !21
  %116 = fadd <8 x float> %111, %wide.masked.load63
  %117 = add nsw i32 %mul26.i, %49
  %118 = sext i32 %117 to i64
  %119 = getelementptr inbounds float, float* %0, i64 %118
  %120 = bitcast float* %119 to <8 x float>*
  %wide.masked.load64 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %120, i32 4, <8 x i1> %48, <8 x float> undef), !tbaa !12, !alias.scope !23
  %121 = fadd <8 x float> %116, %wide.masked.load64
  %122 = add nsw i32 %mul32.i, %49
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds float, float* %0, i64 %123
  %125 = bitcast float* %124 to <8 x float>*
  %wide.masked.load65 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %125, i32 4, <8 x i1> %48, <8 x float> undef), !tbaa !12, !alias.scope !25
  %126 = fadd <8 x float> %121, %wide.masked.load65
  %127 = fmul <8 x float> %126, <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>
  %128 = getelementptr inbounds float, float* %1, i64 %104
  %129 = bitcast float* %128 to <8 x float>*
  call void @llvm.masked.store.v8f32.p0v8f32(<8 x float> %127, <8 x float>* %129, i32 4, <8 x i1> %48), !tbaa !12, !alias.scope !27, !noalias !29, !llvm.access.group !30
  %130 = add i32 %mul.i, %55
  %131 = sext i32 %130 to i64
  %132 = getelementptr inbounds float, float* %0, i64 %131
  %133 = bitcast float* %132 to <8 x float>*
  %wide.masked.load.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %133, i32 4, <8 x i1> %54, <8 x float> undef), !tbaa !12, !alias.scope !16
  %134 = add i32 %130, -1
  %135 = sext i32 %134 to i64
  %136 = getelementptr inbounds float, float* %0, i64 %135
  %137 = bitcast float* %136 to <8 x float>*
  %wide.masked.load62.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %137, i32 4, <8 x i1> %54, <8 x float> undef), !tbaa !12, !alias.scope !19
  %138 = fadd <8 x float> %wide.masked.load.1, %wide.masked.load62.1
  %139 = add i32 %130, 1
  %140 = sext i32 %139 to i64
  %141 = getelementptr inbounds float, float* %0, i64 %140
  %142 = bitcast float* %141 to <8 x float>*
  %wide.masked.load63.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %142, i32 4, <8 x i1> %54, <8 x float> undef), !tbaa !12, !alias.scope !21
  %143 = fadd <8 x float> %138, %wide.masked.load63.1
  %144 = add nsw i32 %mul26.i, %55
  %145 = sext i32 %144 to i64
  %146 = getelementptr inbounds float, float* %0, i64 %145
  %147 = bitcast float* %146 to <8 x float>*
  %wide.masked.load64.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %147, i32 4, <8 x i1> %54, <8 x float> undef), !tbaa !12, !alias.scope !23
  %148 = fadd <8 x float> %143, %wide.masked.load64.1
  %149 = add nsw i32 %mul32.i, %55
  %150 = sext i32 %149 to i64
  %151 = getelementptr inbounds float, float* %0, i64 %150
  %152 = bitcast float* %151 to <8 x float>*
  %wide.masked.load65.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %152, i32 4, <8 x i1> %54, <8 x float> undef), !tbaa !12, !alias.scope !25
  %153 = fadd <8 x float> %148, %wide.masked.load65.1
  %154 = fmul <8 x float> %153, <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>
  %155 = getelementptr inbounds float, float* %1, i64 %131
  %156 = bitcast float* %155 to <8 x float>*
  call void @llvm.masked.store.v8f32.p0v8f32(<8 x float> %154, <8 x float>* %156, i32 4, <8 x i1> %54), !tbaa !12, !alias.scope !27, !noalias !29, !llvm.access.group !30
  %157 = add i32 %mul.i, %61
  %158 = sext i32 %157 to i64
  %159 = getelementptr inbounds float, float* %0, i64 %158
  %160 = bitcast float* %159 to <8 x float>*
  %wide.masked.load.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %160, i32 4, <8 x i1> %60, <8 x float> undef), !tbaa !12, !alias.scope !16
  %161 = add i32 %157, -1
  %162 = sext i32 %161 to i64
  %163 = getelementptr inbounds float, float* %0, i64 %162
  %164 = bitcast float* %163 to <8 x float>*
  %wide.masked.load62.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %164, i32 4, <8 x i1> %60, <8 x float> undef), !tbaa !12, !alias.scope !19
  %165 = fadd <8 x float> %wide.masked.load.2, %wide.masked.load62.2
  %166 = add i32 %157, 1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds float, float* %0, i64 %167
  %169 = bitcast float* %168 to <8 x float>*
  %wide.masked.load63.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %169, i32 4, <8 x i1> %60, <8 x float> undef), !tbaa !12, !alias.scope !21
  %170 = fadd <8 x float> %165, %wide.masked.load63.2
  %171 = add nsw i32 %mul26.i, %61
  %172 = sext i32 %171 to i64
  %173 = getelementptr inbounds float, float* %0, i64 %172
  %174 = bitcast float* %173 to <8 x float>*
  %wide.masked.load64.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %174, i32 4, <8 x i1> %60, <8 x float> undef), !tbaa !12, !alias.scope !23
  %175 = fadd <8 x float> %170, %wide.masked.load64.2
  %176 = add nsw i32 %mul32.i, %61
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds float, float* %0, i64 %177
  %179 = bitcast float* %178 to <8 x float>*
  %wide.masked.load65.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %179, i32 4, <8 x i1> %60, <8 x float> undef), !tbaa !12, !alias.scope !25
  %180 = fadd <8 x float> %175, %wide.masked.load65.2
  %181 = fmul <8 x float> %180, <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>
  %182 = getelementptr inbounds float, float* %1, i64 %158
  %183 = bitcast float* %182 to <8 x float>*
  call void @llvm.masked.store.v8f32.p0v8f32(<8 x float> %181, <8 x float>* %183, i32 4, <8 x i1> %60), !tbaa !12, !alias.scope !27, !noalias !29, !llvm.access.group !30
  %184 = add i32 %mul.i, %67
  %185 = sext i32 %184 to i64
  %186 = getelementptr inbounds float, float* %0, i64 %185
  %187 = bitcast float* %186 to <8 x float>*
  %wide.masked.load.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %187, i32 4, <8 x i1> %66, <8 x float> undef), !tbaa !12, !alias.scope !16
  %188 = add i32 %184, -1
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds float, float* %0, i64 %189
  %191 = bitcast float* %190 to <8 x float>*
  %wide.masked.load62.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %191, i32 4, <8 x i1> %66, <8 x float> undef), !tbaa !12, !alias.scope !19
  %192 = fadd <8 x float> %wide.masked.load.3, %wide.masked.load62.3
  %193 = add i32 %184, 1
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds float, float* %0, i64 %194
  %196 = bitcast float* %195 to <8 x float>*
  %wide.masked.load63.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %196, i32 4, <8 x i1> %66, <8 x float> undef), !tbaa !12, !alias.scope !21
  %197 = fadd <8 x float> %192, %wide.masked.load63.3
  %198 = add nsw i32 %mul26.i, %67
  %199 = sext i32 %198 to i64
  %200 = getelementptr inbounds float, float* %0, i64 %199
  %201 = bitcast float* %200 to <8 x float>*
  %wide.masked.load64.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %201, i32 4, <8 x i1> %66, <8 x float> undef), !tbaa !12, !alias.scope !23
  %202 = fadd <8 x float> %197, %wide.masked.load64.3
  %203 = add nsw i32 %mul32.i, %67
  %204 = sext i32 %203 to i64
  %205 = getelementptr inbounds float, float* %0, i64 %204
  %206 = bitcast float* %205 to <8 x float>*
  %wide.masked.load65.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %206, i32 4, <8 x i1> %66, <8 x float> undef), !tbaa !12, !alias.scope !25
  %207 = fadd <8 x float> %202, %wide.masked.load65.3
  %208 = fmul <8 x float> %207, <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>
  %209 = getelementptr inbounds float, float* %1, i64 %185
  %210 = bitcast float* %209 to <8 x float>*
  call void @llvm.masked.store.v8f32.p0v8f32(<8 x float> %208, <8 x float>* %210, i32 4, <8 x i1> %66), !tbaa !12, !alias.scope !27, !noalias !29, !llvm.access.group !30
  br label %pregion_for_end.i

pregion_for_entry.entry.i.us.us:                  ; preds = %if.end.i.us.us, %pregion_for_entry.entry.i.us.us.preheader
  %_local_id_x.0.us.us = phi i64 [ %216, %if.end.i.us.us ], [ 0, %pregion_for_entry.entry.i.us.us.preheader ]
  %add1.i.i.us.us = add nuw nsw i64 %_local_id_x.0.us.us, %mul.i.i
  %conv2.i.us.us = trunc i64 %add1.i.i.us.us to i32
  %cmp7.i.us.us = icmp sgt i32 %conv2.i.us.us, 0
  %cmp11.i.us.us = icmp sgt i32 %sub.i, %conv2.i.us.us
  %or.cond69.i.us.us = and i1 %cmp11.i.us.us, %cmp7.i.us.us
  br i1 %or.cond69.i.us.us, label %if.then.i.us.us, label %if.end.i.us.us

if.then.i.us.us:                                  ; preds = %pregion_for_entry.entry.i.us.us
  %add.i.us.us = add i32 %mul.i, %conv2.i.us.us
  %idxprom.i.us.us = sext i32 %add.i.us.us to i64
  %arrayidx.i.us.us = getelementptr inbounds float, float* %0, i64 %idxprom.i.us.us
  %211 = load float, float* %arrayidx.i.us.us, align 4, !tbaa !12
  %add15.i.us.us = add i32 %add.i.us.us, -1
  %idxprom16.i.us.us = sext i32 %add15.i.us.us to i64
  %arrayidx17.i.us.us = getelementptr inbounds float, float* %0, i64 %idxprom16.i.us.us
  %212 = load float, float* %arrayidx17.i.us.us, align 4, !tbaa !12
  %add18.i.us.us = fadd float %211, %212
  %add21.i.us.us = add i32 %add.i.us.us, 1
  %idxprom22.i.us.us = sext i32 %add21.i.us.us to i64
  %arrayidx23.i.us.us = getelementptr inbounds float, float* %0, i64 %idxprom22.i.us.us
  %213 = load float, float* %arrayidx23.i.us.us, align 4, !tbaa !12
  %add24.i.us.us = fadd float %add18.i.us.us, %213
  %add27.i.us.us = add nsw i32 %mul26.i, %conv2.i.us.us
  %idxprom28.i.us.us = sext i32 %add27.i.us.us to i64
  %arrayidx29.i.us.us = getelementptr inbounds float, float* %0, i64 %idxprom28.i.us.us
  %214 = load float, float* %arrayidx29.i.us.us, align 4, !tbaa !12
  %add30.i.us.us = fadd float %add24.i.us.us, %214
  %add33.i.us.us = add nsw i32 %mul32.i, %conv2.i.us.us
  %idxprom34.i.us.us = sext i32 %add33.i.us.us to i64
  %arrayidx35.i.us.us = getelementptr inbounds float, float* %0, i64 %idxprom34.i.us.us
  %215 = load float, float* %arrayidx35.i.us.us, align 4, !tbaa !12
  %add36.i.us.us = fadd float %add30.i.us.us, %215
  %mul37.i.us.us = fmul float %add36.i.us.us, 0x3FC99999A0000000
  %arrayidx41.i.us.us = getelementptr inbounds float, float* %1, i64 %idxprom.i.us.us
  store float %mul37.i.us.us, float* %arrayidx41.i.us.us, align 4, !tbaa !12, !llvm.access.group !30
  br label %if.end.i.us.us

if.end.i.us.us:                                   ; preds = %if.then.i.us.us, %pregion_for_entry.entry.i.us.us
  %216 = add nuw nsw i64 %_local_id_x.0.us.us, 1
  %exitcond.not = icmp eq i64 %216, 32
  br i1 %exitcond.not, label %pregion_for_end.i.loopexit, label %pregion_for_entry.entry.i.us.us, !llvm.loop !33

pregion_for_end.i.loopexit:                       ; preds = %if.end.i.us.us
  br label %pregion_for_end.i

pregion_for_end.i:                                ; preds = %pregion_for_end.i.loopexit, %vector.body, %pregion_for_entry.pregion_for_init.i
  %217 = add nuw nsw i64 %_local_id_y.0, 1
  %exitcond3.not = icmp eq i64 %217, 8
  br i1 %exitcond3.not, label %runJacobi2D_kernel1.exit, label %pregion_for_entry.pregion_for_init.i, !llvm.loop !36

runJacobi2D_kernel1.exit:                         ; preds = %pregion_for_end.i
  ret void
}

; Function Attrs: nofree norecurse nounwind
define void @_pocl_kernel_runJacobi2D_kernel1_workgroup(i8** nocapture readonly %0, { [3 x i64], [3 x i64], [3 x i64], i8*, i32*, i32, i32 }* nocapture readnone %1, i64 %2, i64 %3, i64 %4) local_unnamed_addr #1 {
  %6 = bitcast i8** %0 to float***
  %7 = load float**, float*** %6, align 8
  %8 = load float*, float** %7, align 8
  %9 = getelementptr i8*, i8** %0, i64 1
  %10 = bitcast i8** %9 to float***
  %11 = load float**, float*** %10, align 8
  %12 = load float*, float** %11, align 8
  %13 = getelementptr i8*, i8** %0, i64 2
  %14 = bitcast i8** %13 to i32**
  %15 = load i32*, i32** %14, align 8
  %16 = load i32, i32* %15, align 4
  %mul3.i.i.i = shl i64 %3, 3
  %mul.i.i.i = shl i64 %2, 5
  %sub.i.i = add nsw i32 %16, -1
  %17 = trunc i64 %3 to i32
  %18 = mul i32 %16, %17
  %19 = shl i32 %18, 3
  %20 = trunc i64 %2 to i32
  %21 = shl i32 %20, 5
  %22 = add i32 %19, %21
  %23 = zext i32 %16 to i64
  %24 = add i32 %22, -8
  %25 = or i32 %24, 7
  %26 = or i32 %22, 1
  %27 = shl i32 %17, 3
  %28 = or i32 %27, 1
  %29 = mul i32 %16, %28
  %30 = add i32 %29, %21
  %31 = add i32 %27, -1
  %32 = mul i32 %16, %31
  %33 = add i32 %32, %21
  %34 = trunc i64 %3 to i32
  %35 = mul i32 %16, %34
  %36 = shl i32 %35, 3
  %37 = trunc i64 %2 to i32
  %38 = shl i32 %37, 5
  %39 = add i32 %36, %38
  %40 = zext i32 %16 to i64
  %scevgep17 = getelementptr float, float* %12, i64 32
  %41 = shl i32 %34, 3
  %42 = add i32 %41, -1
  %43 = mul i32 %16, %42
  %44 = add i32 %43, %38
  %scevgep22 = getelementptr float, float* %8, i64 32
  %45 = or i32 %41, 1
  %46 = mul i32 %16, %45
  %47 = add i32 %46, %38
  %scevgep27 = getelementptr float, float* %8, i64 32
  %48 = or i32 %39, 1
  %49 = zext i32 %48 to i64
  %scevgep32 = getelementptr float, float* %8, i64 32
  %50 = add i32 %36, %38
  %51 = add i32 %50, -8
  %52 = or i32 %51, 7
  %scevgep37 = getelementptr float, float* %8, i64 32
  %scevgep42 = getelementptr float, float* %8, i64 32
  %bound056 = icmp ult float* %12, %scevgep42
  %bound157 = icmp ult float* %8, %scevgep17
  %found.conflict58 = and i1 %bound056, %bound157
  %broadcast.splatinsert = insertelement <8 x i64> undef, i64 %mul.i.i.i, i32 0
  %broadcast.splat = shufflevector <8 x i64> %broadcast.splatinsert, <8 x i64> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert60 = insertelement <8 x i32> undef, i32 %sub.i.i, i32 0
  %broadcast.splat61 = shufflevector <8 x i32> %broadcast.splatinsert60, <8 x i32> undef, <8 x i32> zeroinitializer
  %53 = trunc <8 x i64> %broadcast.splat to <8 x i32>
  %54 = or <8 x i32> %53, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %55 = icmp sgt <8 x i32> %54, zeroinitializer
  %56 = icmp sgt <8 x i32> %broadcast.splat61, %54
  %57 = and <8 x i1> %56, %55
  %58 = extractelement <8 x i32> %54, i32 0
  %59 = trunc <8 x i64> %broadcast.splat to <8 x i32>
  %60 = or <8 x i32> %59, <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %61 = icmp sgt <8 x i32> %60, zeroinitializer
  %62 = icmp sgt <8 x i32> %broadcast.splat61, %60
  %63 = and <8 x i1> %62, %61
  %64 = extractelement <8 x i32> %60, i32 0
  %65 = trunc <8 x i64> %broadcast.splat to <8 x i32>
  %66 = or <8 x i32> %65, <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %67 = icmp sgt <8 x i32> %66, zeroinitializer
  %68 = icmp sgt <8 x i32> %broadcast.splat61, %66
  %69 = and <8 x i1> %68, %67
  %70 = extractelement <8 x i32> %66, i32 0
  %71 = trunc <8 x i64> %broadcast.splat to <8 x i32>
  %72 = or <8 x i32> %71, <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %73 = icmp sgt <8 x i32> %72, zeroinitializer
  %74 = icmp sgt <8 x i32> %broadcast.splat61, %72
  %75 = and <8 x i1> %74, %73
  %76 = extractelement <8 x i32> %72, i32 0
  br label %pregion_for_entry.pregion_for_init.i.i

pregion_for_entry.pregion_for_init.i.i:           ; preds = %pregion_for_end.i.i, %5
  %_local_id_y.i.0 = phi i64 [ 0, %5 ], [ %226, %pregion_for_end.i.i ]
  %77 = mul i64 %_local_id_y.i.0, %40
  %78 = trunc i64 %77 to i32
  %79 = add i32 %39, %78
  %80 = sext i32 %79 to i64
  %scevgep = getelementptr float, float* %12, i64 %80
  %scevgep18 = getelementptr float, float* %scevgep17, i64 %80
  %81 = trunc i64 %77 to i32
  %82 = add i32 %44, %81
  %83 = sext i32 %82 to i64
  %scevgep20 = getelementptr float, float* %8, i64 %83
  %scevgep23 = getelementptr float, float* %scevgep22, i64 %83
  %84 = trunc i64 %77 to i32
  %85 = add i32 %47, %84
  %86 = sext i32 %85 to i64
  %scevgep25 = getelementptr float, float* %8, i64 %86
  %scevgep28 = getelementptr float, float* %scevgep27, i64 %86
  %87 = add i64 %77, %49
  %sext = shl i64 %87, 32
  %88 = ashr exact i64 %sext, 32
  %scevgep30 = getelementptr float, float* %8, i64 %88
  %scevgep33 = getelementptr float, float* %scevgep32, i64 %88
  %89 = trunc i64 %77 to i32
  %90 = add i32 %52, %89
  %91 = sext i32 %90 to i64
  %scevgep35 = getelementptr float, float* %8, i64 %91
  %scevgep38 = getelementptr float, float* %scevgep37, i64 %91
  %92 = mul i64 %_local_id_y.i.0, %23
  %add6.i.i.i = add nuw nsw i64 %_local_id_y.i.0, %mul3.i.i.i
  %conv.i.i = trunc i64 %add6.i.i.i to i32
  %cmp.i.i = icmp sgt i32 %conv.i.i, 0
  %mul.i.i = mul nsw i32 %16, %conv.i.i
  %add25.i.i = add nuw nsw i32 %conv.i.i, 1
  %mul26.i.i = mul nsw i32 %add25.i.i, %16
  %sub31.i.i = add nsw i32 %conv.i.i, -1
  %mul32.i.i = mul nsw i32 %sub31.i.i, %16
  %cmp4.i.i = icmp sgt i32 %sub.i.i, %conv.i.i
  %or.cond = and i1 %cmp.i.i, %cmp4.i.i
  br i1 %or.cond, label %vector.scevcheck, label %pregion_for_end.i.i

vector.scevcheck:                                 ; preds = %pregion_for_entry.pregion_for_init.i.i
  %93 = trunc i64 %92 to i32
  %94 = add i32 %33, %93
  %95 = trunc i64 %92 to i32
  %96 = add i32 %30, %95
  %97 = trunc i64 %92 to i32
  %98 = add i32 %26, %97
  %99 = trunc i64 %92 to i32
  %100 = add i32 %25, %99
  %101 = trunc i64 %92 to i32
  %102 = add i32 %22, %101
  %103 = icmp sgt i32 %102, 2147483616
  %104 = icmp sgt i32 %100, 2147483616
  %105 = or i1 %103, %104
  %106 = icmp sgt i32 %98, 2147483616
  %107 = or i1 %105, %106
  %108 = icmp sgt i32 %96, 2147483616
  %109 = or i1 %107, %108
  %110 = icmp sgt i32 %94, 2147483616
  %111 = or i1 %109, %110
  br i1 %111, label %pregion_for_entry.entry.i.i.us.us.preheader, label %vector.memcheck

pregion_for_entry.entry.i.i.us.us.preheader:      ; preds = %vector.memcheck, %vector.scevcheck
  br label %pregion_for_entry.entry.i.i.us.us

vector.memcheck:                                  ; preds = %vector.scevcheck
  %bound0 = icmp ult float* %scevgep, %scevgep23
  %bound1 = icmp ult float* %scevgep20, %scevgep18
  %found.conflict = and i1 %bound0, %bound1
  %bound045 = icmp ult float* %scevgep, %scevgep28
  %bound146 = icmp ult float* %scevgep25, %scevgep18
  %found.conflict47 = and i1 %bound045, %bound146
  %conflict.rdx = or i1 %found.conflict, %found.conflict47
  %bound048 = icmp ult float* %scevgep, %scevgep33
  %bound149 = icmp ult float* %scevgep30, %scevgep18
  %found.conflict50 = and i1 %bound048, %bound149
  %conflict.rdx51 = or i1 %conflict.rdx, %found.conflict50
  %bound052 = icmp ult float* %scevgep, %scevgep38
  %bound153 = icmp ult float* %scevgep35, %scevgep18
  %found.conflict54 = and i1 %bound052, %bound153
  %conflict.rdx55 = or i1 %conflict.rdx51, %found.conflict54
  %conflict.rdx59 = or i1 %conflict.rdx55, %found.conflict58
  br i1 %conflict.rdx59, label %pregion_for_entry.entry.i.i.us.us.preheader, label %vector.body

vector.body:                                      ; preds = %vector.memcheck
  %112 = add i32 %mul.i.i, %58
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds float, float* %8, i64 %113
  %115 = bitcast float* %114 to <8 x float>*
  %wide.masked.load = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %115, i32 4, <8 x i1> %57, <8 x float> undef), !tbaa !12, !alias.scope !38
  %116 = add i32 %112, -1
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds float, float* %8, i64 %117
  %119 = bitcast float* %118 to <8 x float>*
  %wide.masked.load62 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %119, i32 4, <8 x i1> %57, <8 x float> undef), !tbaa !12, !alias.scope !41
  %120 = fadd <8 x float> %wide.masked.load, %wide.masked.load62
  %121 = add i32 %112, 1
  %122 = sext i32 %121 to i64
  %123 = getelementptr inbounds float, float* %8, i64 %122
  %124 = bitcast float* %123 to <8 x float>*
  %wide.masked.load63 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %124, i32 4, <8 x i1> %57, <8 x float> undef), !tbaa !12, !alias.scope !43
  %125 = fadd <8 x float> %120, %wide.masked.load63
  %126 = add nsw i32 %mul26.i.i, %58
  %127 = sext i32 %126 to i64
  %128 = getelementptr inbounds float, float* %8, i64 %127
  %129 = bitcast float* %128 to <8 x float>*
  %wide.masked.load64 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %129, i32 4, <8 x i1> %57, <8 x float> undef), !tbaa !12, !alias.scope !45
  %130 = fadd <8 x float> %125, %wide.masked.load64
  %131 = add nsw i32 %mul32.i.i, %58
  %132 = sext i32 %131 to i64
  %133 = getelementptr inbounds float, float* %8, i64 %132
  %134 = bitcast float* %133 to <8 x float>*
  %wide.masked.load65 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %134, i32 4, <8 x i1> %57, <8 x float> undef), !tbaa !12, !alias.scope !47
  %135 = fadd <8 x float> %130, %wide.masked.load65
  %136 = fmul <8 x float> %135, <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>
  %137 = getelementptr inbounds float, float* %12, i64 %113
  %138 = bitcast float* %137 to <8 x float>*
  call void @llvm.masked.store.v8f32.p0v8f32(<8 x float> %136, <8 x float>* %138, i32 4, <8 x i1> %57), !tbaa !12, !alias.scope !49, !noalias !51, !llvm.access.group !30
  %139 = add i32 %mul.i.i, %64
  %140 = sext i32 %139 to i64
  %141 = getelementptr inbounds float, float* %8, i64 %140
  %142 = bitcast float* %141 to <8 x float>*
  %wide.masked.load.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %142, i32 4, <8 x i1> %63, <8 x float> undef), !tbaa !12, !alias.scope !38
  %143 = add i32 %139, -1
  %144 = sext i32 %143 to i64
  %145 = getelementptr inbounds float, float* %8, i64 %144
  %146 = bitcast float* %145 to <8 x float>*
  %wide.masked.load62.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %146, i32 4, <8 x i1> %63, <8 x float> undef), !tbaa !12, !alias.scope !41
  %147 = fadd <8 x float> %wide.masked.load.1, %wide.masked.load62.1
  %148 = add i32 %139, 1
  %149 = sext i32 %148 to i64
  %150 = getelementptr inbounds float, float* %8, i64 %149
  %151 = bitcast float* %150 to <8 x float>*
  %wide.masked.load63.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %151, i32 4, <8 x i1> %63, <8 x float> undef), !tbaa !12, !alias.scope !43
  %152 = fadd <8 x float> %147, %wide.masked.load63.1
  %153 = add nsw i32 %mul26.i.i, %64
  %154 = sext i32 %153 to i64
  %155 = getelementptr inbounds float, float* %8, i64 %154
  %156 = bitcast float* %155 to <8 x float>*
  %wide.masked.load64.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %156, i32 4, <8 x i1> %63, <8 x float> undef), !tbaa !12, !alias.scope !45
  %157 = fadd <8 x float> %152, %wide.masked.load64.1
  %158 = add nsw i32 %mul32.i.i, %64
  %159 = sext i32 %158 to i64
  %160 = getelementptr inbounds float, float* %8, i64 %159
  %161 = bitcast float* %160 to <8 x float>*
  %wide.masked.load65.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %161, i32 4, <8 x i1> %63, <8 x float> undef), !tbaa !12, !alias.scope !47
  %162 = fadd <8 x float> %157, %wide.masked.load65.1
  %163 = fmul <8 x float> %162, <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>
  %164 = getelementptr inbounds float, float* %12, i64 %140
  %165 = bitcast float* %164 to <8 x float>*
  call void @llvm.masked.store.v8f32.p0v8f32(<8 x float> %163, <8 x float>* %165, i32 4, <8 x i1> %63), !tbaa !12, !alias.scope !49, !noalias !51, !llvm.access.group !30
  %166 = add i32 %mul.i.i, %70
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds float, float* %8, i64 %167
  %169 = bitcast float* %168 to <8 x float>*
  %wide.masked.load.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %169, i32 4, <8 x i1> %69, <8 x float> undef), !tbaa !12, !alias.scope !38
  %170 = add i32 %166, -1
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds float, float* %8, i64 %171
  %173 = bitcast float* %172 to <8 x float>*
  %wide.masked.load62.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %173, i32 4, <8 x i1> %69, <8 x float> undef), !tbaa !12, !alias.scope !41
  %174 = fadd <8 x float> %wide.masked.load.2, %wide.masked.load62.2
  %175 = add i32 %166, 1
  %176 = sext i32 %175 to i64
  %177 = getelementptr inbounds float, float* %8, i64 %176
  %178 = bitcast float* %177 to <8 x float>*
  %wide.masked.load63.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %178, i32 4, <8 x i1> %69, <8 x float> undef), !tbaa !12, !alias.scope !43
  %179 = fadd <8 x float> %174, %wide.masked.load63.2
  %180 = add nsw i32 %mul26.i.i, %70
  %181 = sext i32 %180 to i64
  %182 = getelementptr inbounds float, float* %8, i64 %181
  %183 = bitcast float* %182 to <8 x float>*
  %wide.masked.load64.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %183, i32 4, <8 x i1> %69, <8 x float> undef), !tbaa !12, !alias.scope !45
  %184 = fadd <8 x float> %179, %wide.masked.load64.2
  %185 = add nsw i32 %mul32.i.i, %70
  %186 = sext i32 %185 to i64
  %187 = getelementptr inbounds float, float* %8, i64 %186
  %188 = bitcast float* %187 to <8 x float>*
  %wide.masked.load65.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %188, i32 4, <8 x i1> %69, <8 x float> undef), !tbaa !12, !alias.scope !47
  %189 = fadd <8 x float> %184, %wide.masked.load65.2
  %190 = fmul <8 x float> %189, <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>
  %191 = getelementptr inbounds float, float* %12, i64 %167
  %192 = bitcast float* %191 to <8 x float>*
  call void @llvm.masked.store.v8f32.p0v8f32(<8 x float> %190, <8 x float>* %192, i32 4, <8 x i1> %69), !tbaa !12, !alias.scope !49, !noalias !51, !llvm.access.group !30
  %193 = add i32 %mul.i.i, %76
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds float, float* %8, i64 %194
  %196 = bitcast float* %195 to <8 x float>*
  %wide.masked.load.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %196, i32 4, <8 x i1> %75, <8 x float> undef), !tbaa !12, !alias.scope !38
  %197 = add i32 %193, -1
  %198 = sext i32 %197 to i64
  %199 = getelementptr inbounds float, float* %8, i64 %198
  %200 = bitcast float* %199 to <8 x float>*
  %wide.masked.load62.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %200, i32 4, <8 x i1> %75, <8 x float> undef), !tbaa !12, !alias.scope !41
  %201 = fadd <8 x float> %wide.masked.load.3, %wide.masked.load62.3
  %202 = add i32 %193, 1
  %203 = sext i32 %202 to i64
  %204 = getelementptr inbounds float, float* %8, i64 %203
  %205 = bitcast float* %204 to <8 x float>*
  %wide.masked.load63.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %205, i32 4, <8 x i1> %75, <8 x float> undef), !tbaa !12, !alias.scope !43
  %206 = fadd <8 x float> %201, %wide.masked.load63.3
  %207 = add nsw i32 %mul26.i.i, %76
  %208 = sext i32 %207 to i64
  %209 = getelementptr inbounds float, float* %8, i64 %208
  %210 = bitcast float* %209 to <8 x float>*
  %wide.masked.load64.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %210, i32 4, <8 x i1> %75, <8 x float> undef), !tbaa !12, !alias.scope !45
  %211 = fadd <8 x float> %206, %wide.masked.load64.3
  %212 = add nsw i32 %mul32.i.i, %76
  %213 = sext i32 %212 to i64
  %214 = getelementptr inbounds float, float* %8, i64 %213
  %215 = bitcast float* %214 to <8 x float>*
  %wide.masked.load65.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %215, i32 4, <8 x i1> %75, <8 x float> undef), !tbaa !12, !alias.scope !47
  %216 = fadd <8 x float> %211, %wide.masked.load65.3
  %217 = fmul <8 x float> %216, <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>
  %218 = getelementptr inbounds float, float* %12, i64 %194
  %219 = bitcast float* %218 to <8 x float>*
  call void @llvm.masked.store.v8f32.p0v8f32(<8 x float> %217, <8 x float>* %219, i32 4, <8 x i1> %75), !tbaa !12, !alias.scope !49, !noalias !51, !llvm.access.group !30
  br label %pregion_for_end.i.i

pregion_for_entry.entry.i.i.us.us:                ; preds = %if.end.i.i.us.us, %pregion_for_entry.entry.i.i.us.us.preheader
  %_local_id_x.i.0.us.us = phi i64 [ %225, %if.end.i.i.us.us ], [ 0, %pregion_for_entry.entry.i.i.us.us.preheader ]
  %add1.i.i.i.us.us = add nuw nsw i64 %_local_id_x.i.0.us.us, %mul.i.i.i
  %conv2.i.i.us.us = trunc i64 %add1.i.i.i.us.us to i32
  %cmp7.i.i.us.us = icmp sgt i32 %conv2.i.i.us.us, 0
  %cmp11.i.i.us.us = icmp sgt i32 %sub.i.i, %conv2.i.i.us.us
  %or.cond69.i.i.us.us = and i1 %cmp11.i.i.us.us, %cmp7.i.i.us.us
  br i1 %or.cond69.i.i.us.us, label %if.then.i.i.us.us, label %if.end.i.i.us.us

if.then.i.i.us.us:                                ; preds = %pregion_for_entry.entry.i.i.us.us
  %add.i.i.us.us = add i32 %mul.i.i, %conv2.i.i.us.us
  %idxprom.i.i.us.us = sext i32 %add.i.i.us.us to i64
  %arrayidx.i.i.us.us = getelementptr inbounds float, float* %8, i64 %idxprom.i.i.us.us
  %220 = load float, float* %arrayidx.i.i.us.us, align 4, !tbaa !12
  %add15.i.i.us.us = add i32 %add.i.i.us.us, -1
  %idxprom16.i.i.us.us = sext i32 %add15.i.i.us.us to i64
  %arrayidx17.i.i.us.us = getelementptr inbounds float, float* %8, i64 %idxprom16.i.i.us.us
  %221 = load float, float* %arrayidx17.i.i.us.us, align 4, !tbaa !12
  %add18.i.i.us.us = fadd float %220, %221
  %add21.i.i.us.us = add i32 %add.i.i.us.us, 1
  %idxprom22.i.i.us.us = sext i32 %add21.i.i.us.us to i64
  %arrayidx23.i.i.us.us = getelementptr inbounds float, float* %8, i64 %idxprom22.i.i.us.us
  %222 = load float, float* %arrayidx23.i.i.us.us, align 4, !tbaa !12
  %add24.i.i.us.us = fadd float %add18.i.i.us.us, %222
  %add27.i.i.us.us = add nsw i32 %mul26.i.i, %conv2.i.i.us.us
  %idxprom28.i.i.us.us = sext i32 %add27.i.i.us.us to i64
  %arrayidx29.i.i.us.us = getelementptr inbounds float, float* %8, i64 %idxprom28.i.i.us.us
  %223 = load float, float* %arrayidx29.i.i.us.us, align 4, !tbaa !12
  %add30.i.i.us.us = fadd float %add24.i.i.us.us, %223
  %add33.i.i.us.us = add nsw i32 %mul32.i.i, %conv2.i.i.us.us
  %idxprom34.i.i.us.us = sext i32 %add33.i.i.us.us to i64
  %arrayidx35.i.i.us.us = getelementptr inbounds float, float* %8, i64 %idxprom34.i.i.us.us
  %224 = load float, float* %arrayidx35.i.i.us.us, align 4, !tbaa !12
  %add36.i.i.us.us = fadd float %add30.i.i.us.us, %224
  %mul37.i.i.us.us = fmul float %add36.i.i.us.us, 0x3FC99999A0000000
  %arrayidx41.i.i.us.us = getelementptr inbounds float, float* %12, i64 %idxprom.i.i.us.us
  store float %mul37.i.i.us.us, float* %arrayidx41.i.i.us.us, align 4, !tbaa !12, !llvm.access.group !30
  br label %if.end.i.i.us.us

if.end.i.i.us.us:                                 ; preds = %if.then.i.i.us.us, %pregion_for_entry.entry.i.i.us.us
  %225 = add nuw nsw i64 %_local_id_x.i.0.us.us, 1
  %exitcond.not = icmp eq i64 %225, 32
  br i1 %exitcond.not, label %pregion_for_end.i.i.loopexit, label %pregion_for_entry.entry.i.i.us.us, !llvm.loop !52

pregion_for_end.i.i.loopexit:                     ; preds = %if.end.i.i.us.us
  br label %pregion_for_end.i.i

pregion_for_end.i.i:                              ; preds = %pregion_for_end.i.i.loopexit, %vector.body, %pregion_for_entry.pregion_for_init.i.i
  %226 = add nuw nsw i64 %_local_id_y.i.0, 1
  %exitcond3.not = icmp eq i64 %226, 8
  br i1 %exitcond3.not, label %_pocl_kernel_runJacobi2D_kernel1.exit, label %pregion_for_entry.pregion_for_init.i.i, !llvm.loop !36

_pocl_kernel_runJacobi2D_kernel1.exit:            ; preds = %pregion_for_end.i.i
  ret void
}

; Function Attrs: nofree norecurse nounwind
define void @_pocl_kernel_runJacobi2D_kernel1_workgroup_fast(i8** nocapture readonly %0, { [3 x i64], [3 x i64], [3 x i64], i8*, i32*, i32, i32 }* nocapture readnone %1, i64 %2, i64 %3, i64 %4) local_unnamed_addr #1 {
  %6 = bitcast i8** %0 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr i8*, i8** %0, i64 1
  %9 = bitcast i8** %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr i8*, i8** %0, i64 2
  %12 = bitcast i8** %11 to i32**
  %13 = load i32*, i32** %12, align 8
  %14 = load i32, i32* %13, align 4
  %mul3.i.i.i = shl i64 %3, 3
  %mul.i.i.i = shl i64 %2, 5
  %sub.i.i = add nsw i32 %14, -1
  %15 = trunc i64 %3 to i32
  %16 = mul i32 %14, %15
  %17 = shl i32 %16, 3
  %18 = trunc i64 %2 to i32
  %19 = shl i32 %18, 5
  %20 = add i32 %17, %19
  %21 = zext i32 %14 to i64
  %22 = add i32 %20, -8
  %23 = or i32 %22, 7
  %24 = or i32 %20, 1
  %25 = shl i32 %15, 3
  %26 = or i32 %25, 1
  %27 = mul i32 %14, %26
  %28 = add i32 %27, %19
  %29 = add i32 %25, -1
  %30 = mul i32 %14, %29
  %31 = add i32 %30, %19
  %32 = trunc i64 %3 to i32
  %33 = mul i32 %14, %32
  %34 = shl i32 %33, 3
  %35 = trunc i64 %2 to i32
  %36 = shl i32 %35, 5
  %37 = add i32 %34, %36
  %38 = zext i32 %14 to i64
  %scevgep17 = getelementptr float, float* %10, i64 32
  %39 = shl i32 %32, 3
  %40 = add i32 %39, -1
  %41 = mul i32 %14, %40
  %42 = add i32 %41, %36
  %scevgep22 = getelementptr float, float* %7, i64 32
  %43 = or i32 %39, 1
  %44 = mul i32 %14, %43
  %45 = add i32 %44, %36
  %scevgep27 = getelementptr float, float* %7, i64 32
  %46 = or i32 %37, 1
  %47 = zext i32 %46 to i64
  %scevgep32 = getelementptr float, float* %7, i64 32
  %48 = add i32 %34, %36
  %49 = add i32 %48, -8
  %50 = or i32 %49, 7
  %scevgep37 = getelementptr float, float* %7, i64 32
  %scevgep42 = getelementptr float, float* %7, i64 32
  %bound056 = icmp ult float* %10, %scevgep42
  %bound157 = icmp ult float* %7, %scevgep17
  %found.conflict58 = and i1 %bound056, %bound157
  %broadcast.splatinsert = insertelement <8 x i64> undef, i64 %mul.i.i.i, i32 0
  %broadcast.splat = shufflevector <8 x i64> %broadcast.splatinsert, <8 x i64> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert60 = insertelement <8 x i32> undef, i32 %sub.i.i, i32 0
  %broadcast.splat61 = shufflevector <8 x i32> %broadcast.splatinsert60, <8 x i32> undef, <8 x i32> zeroinitializer
  %51 = trunc <8 x i64> %broadcast.splat to <8 x i32>
  %52 = or <8 x i32> %51, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %53 = icmp sgt <8 x i32> %52, zeroinitializer
  %54 = icmp sgt <8 x i32> %broadcast.splat61, %52
  %55 = and <8 x i1> %54, %53
  %56 = extractelement <8 x i32> %52, i32 0
  %57 = trunc <8 x i64> %broadcast.splat to <8 x i32>
  %58 = or <8 x i32> %57, <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %59 = icmp sgt <8 x i32> %58, zeroinitializer
  %60 = icmp sgt <8 x i32> %broadcast.splat61, %58
  %61 = and <8 x i1> %60, %59
  %62 = extractelement <8 x i32> %58, i32 0
  %63 = trunc <8 x i64> %broadcast.splat to <8 x i32>
  %64 = or <8 x i32> %63, <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %65 = icmp sgt <8 x i32> %64, zeroinitializer
  %66 = icmp sgt <8 x i32> %broadcast.splat61, %64
  %67 = and <8 x i1> %66, %65
  %68 = extractelement <8 x i32> %64, i32 0
  %69 = trunc <8 x i64> %broadcast.splat to <8 x i32>
  %70 = or <8 x i32> %69, <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  %71 = icmp sgt <8 x i32> %70, zeroinitializer
  %72 = icmp sgt <8 x i32> %broadcast.splat61, %70
  %73 = and <8 x i1> %72, %71
  %74 = extractelement <8 x i32> %70, i32 0
  br label %pregion_for_entry.pregion_for_init.i.i

pregion_for_entry.pregion_for_init.i.i:           ; preds = %pregion_for_end.i.i, %5
  %_local_id_y.i.0 = phi i64 [ 0, %5 ], [ %224, %pregion_for_end.i.i ]
  %75 = mul i64 %_local_id_y.i.0, %38
  %76 = trunc i64 %75 to i32
  %77 = add i32 %37, %76
  %78 = sext i32 %77 to i64
  %scevgep = getelementptr float, float* %10, i64 %78
  %scevgep18 = getelementptr float, float* %scevgep17, i64 %78
  %79 = trunc i64 %75 to i32
  %80 = add i32 %42, %79
  %81 = sext i32 %80 to i64
  %scevgep20 = getelementptr float, float* %7, i64 %81
  %scevgep23 = getelementptr float, float* %scevgep22, i64 %81
  %82 = trunc i64 %75 to i32
  %83 = add i32 %45, %82
  %84 = sext i32 %83 to i64
  %scevgep25 = getelementptr float, float* %7, i64 %84
  %scevgep28 = getelementptr float, float* %scevgep27, i64 %84
  %85 = add i64 %75, %47
  %sext = shl i64 %85, 32
  %86 = ashr exact i64 %sext, 32
  %scevgep30 = getelementptr float, float* %7, i64 %86
  %scevgep33 = getelementptr float, float* %scevgep32, i64 %86
  %87 = trunc i64 %75 to i32
  %88 = add i32 %50, %87
  %89 = sext i32 %88 to i64
  %scevgep35 = getelementptr float, float* %7, i64 %89
  %scevgep38 = getelementptr float, float* %scevgep37, i64 %89
  %90 = mul i64 %_local_id_y.i.0, %21
  %add6.i.i.i = add nuw nsw i64 %_local_id_y.i.0, %mul3.i.i.i
  %conv.i.i = trunc i64 %add6.i.i.i to i32
  %cmp.i.i = icmp sgt i32 %conv.i.i, 0
  %mul.i.i = mul nsw i32 %14, %conv.i.i
  %add25.i.i = add nuw nsw i32 %conv.i.i, 1
  %mul26.i.i = mul nsw i32 %add25.i.i, %14
  %sub31.i.i = add nsw i32 %conv.i.i, -1
  %mul32.i.i = mul nsw i32 %sub31.i.i, %14
  %cmp4.i.i = icmp sgt i32 %sub.i.i, %conv.i.i
  %or.cond = and i1 %cmp.i.i, %cmp4.i.i
  br i1 %or.cond, label %vector.scevcheck, label %pregion_for_end.i.i

vector.scevcheck:                                 ; preds = %pregion_for_entry.pregion_for_init.i.i
  %91 = trunc i64 %90 to i32
  %92 = add i32 %31, %91
  %93 = trunc i64 %90 to i32
  %94 = add i32 %28, %93
  %95 = trunc i64 %90 to i32
  %96 = add i32 %24, %95
  %97 = trunc i64 %90 to i32
  %98 = add i32 %23, %97
  %99 = trunc i64 %90 to i32
  %100 = add i32 %20, %99
  %101 = icmp sgt i32 %100, 2147483616
  %102 = icmp sgt i32 %98, 2147483616
  %103 = or i1 %101, %102
  %104 = icmp sgt i32 %96, 2147483616
  %105 = or i1 %103, %104
  %106 = icmp sgt i32 %94, 2147483616
  %107 = or i1 %105, %106
  %108 = icmp sgt i32 %92, 2147483616
  %109 = or i1 %107, %108
  br i1 %109, label %pregion_for_entry.entry.i.i.us.us.preheader, label %vector.memcheck

pregion_for_entry.entry.i.i.us.us.preheader:      ; preds = %vector.memcheck, %vector.scevcheck
  br label %pregion_for_entry.entry.i.i.us.us

vector.memcheck:                                  ; preds = %vector.scevcheck
  %bound0 = icmp ult float* %scevgep, %scevgep23
  %bound1 = icmp ult float* %scevgep20, %scevgep18
  %found.conflict = and i1 %bound0, %bound1
  %bound045 = icmp ult float* %scevgep, %scevgep28
  %bound146 = icmp ult float* %scevgep25, %scevgep18
  %found.conflict47 = and i1 %bound045, %bound146
  %conflict.rdx = or i1 %found.conflict, %found.conflict47
  %bound048 = icmp ult float* %scevgep, %scevgep33
  %bound149 = icmp ult float* %scevgep30, %scevgep18
  %found.conflict50 = and i1 %bound048, %bound149
  %conflict.rdx51 = or i1 %conflict.rdx, %found.conflict50
  %bound052 = icmp ult float* %scevgep, %scevgep38
  %bound153 = icmp ult float* %scevgep35, %scevgep18
  %found.conflict54 = and i1 %bound052, %bound153
  %conflict.rdx55 = or i1 %conflict.rdx51, %found.conflict54
  %conflict.rdx59 = or i1 %conflict.rdx55, %found.conflict58
  br i1 %conflict.rdx59, label %pregion_for_entry.entry.i.i.us.us.preheader, label %vector.body

vector.body:                                      ; preds = %vector.memcheck
  %110 = add i32 %mul.i.i, %56
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds float, float* %7, i64 %111
  %113 = bitcast float* %112 to <8 x float>*
  %wide.masked.load = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %113, i32 4, <8 x i1> %55, <8 x float> undef), !tbaa !12, !alias.scope !53
  %114 = add i32 %110, -1
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds float, float* %7, i64 %115
  %117 = bitcast float* %116 to <8 x float>*
  %wide.masked.load62 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %117, i32 4, <8 x i1> %55, <8 x float> undef), !tbaa !12, !alias.scope !56
  %118 = fadd <8 x float> %wide.masked.load, %wide.masked.load62
  %119 = add i32 %110, 1
  %120 = sext i32 %119 to i64
  %121 = getelementptr inbounds float, float* %7, i64 %120
  %122 = bitcast float* %121 to <8 x float>*
  %wide.masked.load63 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %122, i32 4, <8 x i1> %55, <8 x float> undef), !tbaa !12, !alias.scope !58
  %123 = fadd <8 x float> %118, %wide.masked.load63
  %124 = add nsw i32 %mul26.i.i, %56
  %125 = sext i32 %124 to i64
  %126 = getelementptr inbounds float, float* %7, i64 %125
  %127 = bitcast float* %126 to <8 x float>*
  %wide.masked.load64 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %127, i32 4, <8 x i1> %55, <8 x float> undef), !tbaa !12, !alias.scope !60
  %128 = fadd <8 x float> %123, %wide.masked.load64
  %129 = add nsw i32 %mul32.i.i, %56
  %130 = sext i32 %129 to i64
  %131 = getelementptr inbounds float, float* %7, i64 %130
  %132 = bitcast float* %131 to <8 x float>*
  %wide.masked.load65 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %132, i32 4, <8 x i1> %55, <8 x float> undef), !tbaa !12, !alias.scope !62
  %133 = fadd <8 x float> %128, %wide.masked.load65
  %134 = fmul <8 x float> %133, <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>
  %135 = getelementptr inbounds float, float* %10, i64 %111
  %136 = bitcast float* %135 to <8 x float>*
  call void @llvm.masked.store.v8f32.p0v8f32(<8 x float> %134, <8 x float>* %136, i32 4, <8 x i1> %55), !tbaa !12, !alias.scope !64, !noalias !66, !llvm.access.group !30
  %137 = add i32 %mul.i.i, %62
  %138 = sext i32 %137 to i64
  %139 = getelementptr inbounds float, float* %7, i64 %138
  %140 = bitcast float* %139 to <8 x float>*
  %wide.masked.load.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %140, i32 4, <8 x i1> %61, <8 x float> undef), !tbaa !12, !alias.scope !53
  %141 = add i32 %137, -1
  %142 = sext i32 %141 to i64
  %143 = getelementptr inbounds float, float* %7, i64 %142
  %144 = bitcast float* %143 to <8 x float>*
  %wide.masked.load62.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %144, i32 4, <8 x i1> %61, <8 x float> undef), !tbaa !12, !alias.scope !56
  %145 = fadd <8 x float> %wide.masked.load.1, %wide.masked.load62.1
  %146 = add i32 %137, 1
  %147 = sext i32 %146 to i64
  %148 = getelementptr inbounds float, float* %7, i64 %147
  %149 = bitcast float* %148 to <8 x float>*
  %wide.masked.load63.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %149, i32 4, <8 x i1> %61, <8 x float> undef), !tbaa !12, !alias.scope !58
  %150 = fadd <8 x float> %145, %wide.masked.load63.1
  %151 = add nsw i32 %mul26.i.i, %62
  %152 = sext i32 %151 to i64
  %153 = getelementptr inbounds float, float* %7, i64 %152
  %154 = bitcast float* %153 to <8 x float>*
  %wide.masked.load64.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %154, i32 4, <8 x i1> %61, <8 x float> undef), !tbaa !12, !alias.scope !60
  %155 = fadd <8 x float> %150, %wide.masked.load64.1
  %156 = add nsw i32 %mul32.i.i, %62
  %157 = sext i32 %156 to i64
  %158 = getelementptr inbounds float, float* %7, i64 %157
  %159 = bitcast float* %158 to <8 x float>*
  %wide.masked.load65.1 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %159, i32 4, <8 x i1> %61, <8 x float> undef), !tbaa !12, !alias.scope !62
  %160 = fadd <8 x float> %155, %wide.masked.load65.1
  %161 = fmul <8 x float> %160, <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>
  %162 = getelementptr inbounds float, float* %10, i64 %138
  %163 = bitcast float* %162 to <8 x float>*
  call void @llvm.masked.store.v8f32.p0v8f32(<8 x float> %161, <8 x float>* %163, i32 4, <8 x i1> %61), !tbaa !12, !alias.scope !64, !noalias !66, !llvm.access.group !30
  %164 = add i32 %mul.i.i, %68
  %165 = sext i32 %164 to i64
  %166 = getelementptr inbounds float, float* %7, i64 %165
  %167 = bitcast float* %166 to <8 x float>*
  %wide.masked.load.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %167, i32 4, <8 x i1> %67, <8 x float> undef), !tbaa !12, !alias.scope !53
  %168 = add i32 %164, -1
  %169 = sext i32 %168 to i64
  %170 = getelementptr inbounds float, float* %7, i64 %169
  %171 = bitcast float* %170 to <8 x float>*
  %wide.masked.load62.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %171, i32 4, <8 x i1> %67, <8 x float> undef), !tbaa !12, !alias.scope !56
  %172 = fadd <8 x float> %wide.masked.load.2, %wide.masked.load62.2
  %173 = add i32 %164, 1
  %174 = sext i32 %173 to i64
  %175 = getelementptr inbounds float, float* %7, i64 %174
  %176 = bitcast float* %175 to <8 x float>*
  %wide.masked.load63.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %176, i32 4, <8 x i1> %67, <8 x float> undef), !tbaa !12, !alias.scope !58
  %177 = fadd <8 x float> %172, %wide.masked.load63.2
  %178 = add nsw i32 %mul26.i.i, %68
  %179 = sext i32 %178 to i64
  %180 = getelementptr inbounds float, float* %7, i64 %179
  %181 = bitcast float* %180 to <8 x float>*
  %wide.masked.load64.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %181, i32 4, <8 x i1> %67, <8 x float> undef), !tbaa !12, !alias.scope !60
  %182 = fadd <8 x float> %177, %wide.masked.load64.2
  %183 = add nsw i32 %mul32.i.i, %68
  %184 = sext i32 %183 to i64
  %185 = getelementptr inbounds float, float* %7, i64 %184
  %186 = bitcast float* %185 to <8 x float>*
  %wide.masked.load65.2 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %186, i32 4, <8 x i1> %67, <8 x float> undef), !tbaa !12, !alias.scope !62
  %187 = fadd <8 x float> %182, %wide.masked.load65.2
  %188 = fmul <8 x float> %187, <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>
  %189 = getelementptr inbounds float, float* %10, i64 %165
  %190 = bitcast float* %189 to <8 x float>*
  call void @llvm.masked.store.v8f32.p0v8f32(<8 x float> %188, <8 x float>* %190, i32 4, <8 x i1> %67), !tbaa !12, !alias.scope !64, !noalias !66, !llvm.access.group !30
  %191 = add i32 %mul.i.i, %74
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds float, float* %7, i64 %192
  %194 = bitcast float* %193 to <8 x float>*
  %wide.masked.load.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %194, i32 4, <8 x i1> %73, <8 x float> undef), !tbaa !12, !alias.scope !53
  %195 = add i32 %191, -1
  %196 = sext i32 %195 to i64
  %197 = getelementptr inbounds float, float* %7, i64 %196
  %198 = bitcast float* %197 to <8 x float>*
  %wide.masked.load62.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %198, i32 4, <8 x i1> %73, <8 x float> undef), !tbaa !12, !alias.scope !56
  %199 = fadd <8 x float> %wide.masked.load.3, %wide.masked.load62.3
  %200 = add i32 %191, 1
  %201 = sext i32 %200 to i64
  %202 = getelementptr inbounds float, float* %7, i64 %201
  %203 = bitcast float* %202 to <8 x float>*
  %wide.masked.load63.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %203, i32 4, <8 x i1> %73, <8 x float> undef), !tbaa !12, !alias.scope !58
  %204 = fadd <8 x float> %199, %wide.masked.load63.3
  %205 = add nsw i32 %mul26.i.i, %74
  %206 = sext i32 %205 to i64
  %207 = getelementptr inbounds float, float* %7, i64 %206
  %208 = bitcast float* %207 to <8 x float>*
  %wide.masked.load64.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %208, i32 4, <8 x i1> %73, <8 x float> undef), !tbaa !12, !alias.scope !60
  %209 = fadd <8 x float> %204, %wide.masked.load64.3
  %210 = add nsw i32 %mul32.i.i, %74
  %211 = sext i32 %210 to i64
  %212 = getelementptr inbounds float, float* %7, i64 %211
  %213 = bitcast float* %212 to <8 x float>*
  %wide.masked.load65.3 = call <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>* %213, i32 4, <8 x i1> %73, <8 x float> undef), !tbaa !12, !alias.scope !62
  %214 = fadd <8 x float> %209, %wide.masked.load65.3
  %215 = fmul <8 x float> %214, <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>
  %216 = getelementptr inbounds float, float* %10, i64 %192
  %217 = bitcast float* %216 to <8 x float>*
  call void @llvm.masked.store.v8f32.p0v8f32(<8 x float> %215, <8 x float>* %217, i32 4, <8 x i1> %73), !tbaa !12, !alias.scope !64, !noalias !66, !llvm.access.group !30
  br label %pregion_for_end.i.i

pregion_for_entry.entry.i.i.us.us:                ; preds = %if.end.i.i.us.us, %pregion_for_entry.entry.i.i.us.us.preheader
  %_local_id_x.i.0.us.us = phi i64 [ %223, %if.end.i.i.us.us ], [ 0, %pregion_for_entry.entry.i.i.us.us.preheader ]
  %add1.i.i.i.us.us = add nuw nsw i64 %_local_id_x.i.0.us.us, %mul.i.i.i
  %conv2.i.i.us.us = trunc i64 %add1.i.i.i.us.us to i32
  %cmp7.i.i.us.us = icmp sgt i32 %conv2.i.i.us.us, 0
  %cmp11.i.i.us.us = icmp sgt i32 %sub.i.i, %conv2.i.i.us.us
  %or.cond69.i.i.us.us = and i1 %cmp11.i.i.us.us, %cmp7.i.i.us.us
  br i1 %or.cond69.i.i.us.us, label %if.then.i.i.us.us, label %if.end.i.i.us.us

if.then.i.i.us.us:                                ; preds = %pregion_for_entry.entry.i.i.us.us
  %add.i.i.us.us = add i32 %mul.i.i, %conv2.i.i.us.us
  %idxprom.i.i.us.us = sext i32 %add.i.i.us.us to i64
  %arrayidx.i.i.us.us = getelementptr inbounds float, float* %7, i64 %idxprom.i.i.us.us
  %218 = load float, float* %arrayidx.i.i.us.us, align 4, !tbaa !12
  %add15.i.i.us.us = add i32 %add.i.i.us.us, -1
  %idxprom16.i.i.us.us = sext i32 %add15.i.i.us.us to i64
  %arrayidx17.i.i.us.us = getelementptr inbounds float, float* %7, i64 %idxprom16.i.i.us.us
  %219 = load float, float* %arrayidx17.i.i.us.us, align 4, !tbaa !12
  %add18.i.i.us.us = fadd float %218, %219
  %add21.i.i.us.us = add i32 %add.i.i.us.us, 1
  %idxprom22.i.i.us.us = sext i32 %add21.i.i.us.us to i64
  %arrayidx23.i.i.us.us = getelementptr inbounds float, float* %7, i64 %idxprom22.i.i.us.us
  %220 = load float, float* %arrayidx23.i.i.us.us, align 4, !tbaa !12
  %add24.i.i.us.us = fadd float %add18.i.i.us.us, %220
  %add27.i.i.us.us = add nsw i32 %mul26.i.i, %conv2.i.i.us.us
  %idxprom28.i.i.us.us = sext i32 %add27.i.i.us.us to i64
  %arrayidx29.i.i.us.us = getelementptr inbounds float, float* %7, i64 %idxprom28.i.i.us.us
  %221 = load float, float* %arrayidx29.i.i.us.us, align 4, !tbaa !12
  %add30.i.i.us.us = fadd float %add24.i.i.us.us, %221
  %add33.i.i.us.us = add nsw i32 %mul32.i.i, %conv2.i.i.us.us
  %idxprom34.i.i.us.us = sext i32 %add33.i.i.us.us to i64
  %arrayidx35.i.i.us.us = getelementptr inbounds float, float* %7, i64 %idxprom34.i.i.us.us
  %222 = load float, float* %arrayidx35.i.i.us.us, align 4, !tbaa !12
  %add36.i.i.us.us = fadd float %add30.i.i.us.us, %222
  %mul37.i.i.us.us = fmul float %add36.i.i.us.us, 0x3FC99999A0000000
  %arrayidx41.i.i.us.us = getelementptr inbounds float, float* %10, i64 %idxprom.i.i.us.us
  store float %mul37.i.i.us.us, float* %arrayidx41.i.i.us.us, align 4, !tbaa !12, !llvm.access.group !30
  br label %if.end.i.i.us.us

if.end.i.i.us.us:                                 ; preds = %if.then.i.i.us.us, %pregion_for_entry.entry.i.i.us.us
  %223 = add nuw nsw i64 %_local_id_x.i.0.us.us, 1
  %exitcond.not = icmp eq i64 %223, 32
  br i1 %exitcond.not, label %pregion_for_end.i.i.loopexit, label %pregion_for_entry.entry.i.i.us.us, !llvm.loop !67

pregion_for_end.i.i.loopexit:                     ; preds = %if.end.i.i.us.us
  br label %pregion_for_end.i.i

pregion_for_end.i.i:                              ; preds = %pregion_for_end.i.i.loopexit, %vector.body, %pregion_for_entry.pregion_for_init.i.i
  %224 = add nuw nsw i64 %_local_id_y.i.0, 1
  %exitcond3.not = icmp eq i64 %224, 8
  br i1 %exitcond3.not, label %_pocl_kernel_runJacobi2D_kernel1.exit, label %pregion_for_entry.pregion_for_init.i.i, !llvm.loop !36

_pocl_kernel_runJacobi2D_kernel1.exit:            ; preds = %pregion_for_end.i.i
  ret void
}

; Function Attrs: argmemonly nounwind readonly willreturn
declare <8 x float> @llvm.masked.load.v8f32.p0v8f32(<8 x float>*, i32 immarg, <8 x i1>, <8 x float>) #2

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.masked.store.v8f32.p0v8f32(<8 x float>, <8 x float>*, i32 immarg, <8 x i1>) #3

attributes #0 = { alwaysinline nofree norecurse nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-builtins" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "stackrealign" "target-cpu"="skylake" "target-features"="+adx,+aes,+avx,+avx2,+bmi,+bmi2,+clflushopt,+cx16,+cx8,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+popcnt,+prfchw,+rdrnd,+rdseed,+sahf,+sgx,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsavec,+xsaveopt,+xsaves" "uniform-work-group-size"="true" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nofree norecurse nounwind }
attributes #2 = { argmemonly nounwind readonly willreturn }
attributes #3 = { argmemonly nounwind willreturn }

!llvm.module.flags = !{!0, !1, !2}
!opencl.ocl.version = !{!3}
!llvm.ident = !{!4}
!opencl.spir.version = !{!3}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 7, !"PIE Level", i32 2}
!3 = !{i32 1, i32 2}
!4 = !{!"clang version 11.0.0 (git@github.com:llvm/llvm-project.git 91e89f9a5115b0f83b8f026e1ad0e6d1f885fa9b)"}
!5 = !{i32 1, i32 1, i32 0}
!6 = !{!"none", !"none", !"none"}
!7 = !{!"DATA_TYPE*", !"DATA_TYPE*", !"int"}
!8 = !{!"float*", !"float*", !"int"}
!9 = !{!"", !"", !""}
!10 = !{!"A", !"B", !"n"}
!11 = !{i32 1}
!12 = !{!13, !13, i64 0}
!13 = !{!"float", !14, i64 0}
!14 = !{!"omnipotent char", !15, i64 0}
!15 = !{!"Simple C/C++ TBAA"}
!16 = !{!17}
!17 = distinct !{!17, !18}
!18 = distinct !{!18, !"LVerDomain"}
!19 = !{!20}
!20 = distinct !{!20, !18}
!21 = !{!22}
!22 = distinct !{!22, !18}
!23 = !{!24}
!24 = distinct !{!24, !18}
!25 = !{!26}
!26 = distinct !{!26, !18}
!27 = !{!28}
!28 = distinct !{!28, !18}
!29 = !{!26, !24, !22, !20, !17}
!30 = !{!31, !32}
!31 = distinct !{}
!32 = distinct !{}
!33 = distinct !{!33, !34, !35}
!34 = !{!"llvm.loop.parallel_accesses", !31}
!35 = !{!"llvm.loop.isvectorized", i32 1}
!36 = distinct !{!36, !37}
!37 = !{!"llvm.loop.parallel_accesses", !32}
!38 = !{!39}
!39 = distinct !{!39, !40}
!40 = distinct !{!40, !"LVerDomain"}
!41 = !{!42}
!42 = distinct !{!42, !40}
!43 = !{!44}
!44 = distinct !{!44, !40}
!45 = !{!46}
!46 = distinct !{!46, !40}
!47 = !{!48}
!48 = distinct !{!48, !40}
!49 = !{!50}
!50 = distinct !{!50, !40}
!51 = !{!48, !46, !44, !42, !39}
!52 = distinct !{!52, !34, !35}
!53 = !{!54}
!54 = distinct !{!54, !55}
!55 = distinct !{!55, !"LVerDomain"}
!56 = !{!57}
!57 = distinct !{!57, !55}
!58 = !{!59}
!59 = distinct !{!59, !55}
!60 = !{!61}
!61 = distinct !{!61, !55}
!62 = !{!63}
!63 = distinct !{!63, !55}
!64 = !{!65}
!65 = distinct !{!65, !55}
!66 = !{!63, !61, !59, !57, !54}
!67 = distinct !{!67, !34, !35}
